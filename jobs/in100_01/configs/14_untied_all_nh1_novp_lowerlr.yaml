model: vision_transformer_tiny_patch16_128
untied: "1,1,1"
num_heads: 1
qk_head_dim: 64
no_vp: true
lr: 1.0e-04
desc: "all untied weights with single head attention and no value or proj and lower lr"

dataset: imagenet-100
crop_min_scale: 0.33334
hflip: 0.5
color_jitter: 0.4
epochs: 50
amp: true
wandb: true
figure_interval: 5
