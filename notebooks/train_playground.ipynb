{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columnformer training playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If working on colab, you need to install the project. Skip these steps if working from a local installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "76tI5bzpxIE5"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "INSTALL=false\n",
    "\n",
    "if [[ $INSTALL == true ]]; then\n",
    "    git clone https://github.com/clane9/columnformers.git\n",
    "    cd columnformers\n",
    "\n",
    "    pip install -U pip\n",
    "    pip install -r requirements.txt\n",
    "    pip install -e .\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from timm.utils import AverageMeter, random_seed\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import columnformers.utils as ut\n",
    "from columnformers.data import create_dataset, create_loader, list_datasets\n",
    "from columnformers.inspection.metrics import Accuracy\n",
    "from columnformers.models import create_model, list_models\n",
    "from columnformers.tasks import ImageClassification, Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    # Model\n",
    "    model: str = \"vision_columnformer_r_tiny_patch16_128\"\n",
    "    num_heads: Optional[int] = None\n",
    "    mlp_ratio: Optional[int] = None\n",
    "    untied: Optional[Union[bool, Tuple[bool, bool, bool]]] = None\n",
    "    skip_attn: Optional[bool] = None\n",
    "    attn_bias: Optional[bool] = None\n",
    "    qk_head_dim: Optional[int] = None\n",
    "    no_vp: Optional[bool] = None\n",
    "    init_local_attn: Optional[bool] = None\n",
    "    global_pool: Literal[\"avg\", \"spatial\"] = \"avg\"\n",
    "    pos_embed: bool = True\n",
    "    drop_rate: float = 0.0\n",
    "    proj_drop_rate: float = 0.0\n",
    "    attn_drop_rate: float = 0.0\n",
    "    wiring_lambd: float = 0.0\n",
    "    # Dataset\n",
    "    dataset: str = \"imagenet100\"\n",
    "    crop_min_scale: float = 1.0\n",
    "    hflip: float = 0.01\n",
    "    color_jitter: Optional[float] = None\n",
    "    keep_in_memory: bool = False\n",
    "    workers: int = 4\n",
    "    # Optimization\n",
    "    epochs: int = 100\n",
    "    batch_size: int = 256\n",
    "    lr: float = 6e-4\n",
    "    decay_lr: bool = True\n",
    "    warmup_fraction: float = 0.1\n",
    "    weight_decay: float = 0.05\n",
    "    clip_grad: Optional[float] = 1.0\n",
    "    # Logistics\n",
    "    use_cuda: bool = True\n",
    "    log_interval: int = 10\n",
    "    debug: bool = False\n",
    "    seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: \n",
      "vision_transformer_tiny_patch16_128\n",
      "vision_columnformer_ff_tiny_patch16_128\n",
      "vision_columnformer_r_tiny_patch16_128 \n",
      "\n",
      "Available datasets: \n",
      "imagenet-100\n",
      "micro-imagenet-100\n",
      "debug-100\n"
     ]
    }
   ],
   "source": [
    "print(\"Available models:\", \"\\n\" + \"\\n\".join(list_models()), \"\\n\")\n",
    "print(\"Available datasets:\", \"\\n\" + \"\\n\".join(list_datasets()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: vision_columnformer_r_tiny_patch16_128\n",
      "num_heads: null\n",
      "mlp_ratio: null\n",
      "untied: null\n",
      "skip_attn: null\n",
      "attn_bias: false\n",
      "qk_head_dim: null\n",
      "no_vp: null\n",
      "init_local_attn: false\n",
      "global_pool: avg\n",
      "pos_embed: true\n",
      "drop_rate: 0.0\n",
      "proj_drop_rate: 0.0\n",
      "attn_drop_rate: 0.0\n",
      "wiring_lambd: 0.0\n",
      "dataset: micro-imagenet-100\n",
      "crop_min_scale: 1.0\n",
      "hflip: 0.01\n",
      "color_jitter: null\n",
      "keep_in_memory: true\n",
      "workers: 4\n",
      "epochs: 10\n",
      "batch_size: 256\n",
      "lr: 0.0001\n",
      "decay_lr: false\n",
      "warmup_fraction: 0.0\n",
      "weight_decay: 0.05\n",
      "clip_grad: 1.0\n",
      "use_cuda: true\n",
      "log_interval: 10\n",
      "debug: false\n",
      "seed: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(\n",
    "    model=\"vision_columnformer_r_tiny_patch16_128\",\n",
    "    attn_bias=False,\n",
    "    init_local_attn=False,\n",
    "    pos_embed=True,\n",
    "    dataset=\"micro-imagenet-100\",\n",
    "    keep_in_memory=True,\n",
    "    epochs=10,\n",
    "    lr=1e-4,\n",
    "    decay_lr=False,\n",
    "    warmup_fraction=0.0,\n",
    ")\n",
    "\n",
    "print(yaml.safe_dump(args.__dict__, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if args.use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f583b4d77035413ba8f3f0f967fee34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d49b2308914753a7e983f514cda892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(\n",
    "    args.dataset,\n",
    "    min_scale=args.crop_min_scale,\n",
    "    hflip=args.hflip,\n",
    "    color_jitter=args.color_jitter,\n",
    "    keep_in_memory=args.keep_in_memory,\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {}\n",
    "for split, ds in dataset.items():\n",
    "    loaders[split] = create_loader(\n",
    "        ds,\n",
    "        shuffle=True,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=False,\n",
    "        num_workers=args.workers,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': (torch.Size([256, 3, 128, 128]), torch.float32, device(type='cuda', index=0)), 'label': (torch.Size([256]), torch.int64, device(type='cuda', index=0))}\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(iter(loaders[\"train\"]))\n",
    "\n",
    "print({k: (v.shape, v.dtype, v.device) for k, v in first_batch.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = dataset[\"train\"].features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionColumnformer(\n",
      "  pos_embed=True\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (encoder): Columnformer(\n",
      "    depth=6, recurrent=True, geometry=(384, 384), init_local_attn=False, local_attn_sigma=2.0\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        skip_attn=False\n",
      "        (norm1): UntiedLayerNorm(384, 384, eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          bias=False\n",
      "          (q): UntiedLinear(384, 384, 64, bias=True)\n",
      "          (k): UntiedLinear(384, 384, 64, bias=True)\n",
      "          (v): Identity()\n",
      "          (proj): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm2): UntiedLayerNorm(384, 384, eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): UntiedLinear(384, 384, 64, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): UntiedLinear(384, 64, 384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  (pool): None\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Linear(in_features=384, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    args.model,\n",
    "    num_heads=args.num_heads,\n",
    "    mlp_ratio=args.mlp_ratio,\n",
    "    untied=args.untied,\n",
    "    skip_attn=args.skip_attn,\n",
    "    attn_bias=args.attn_bias,\n",
    "    qk_head_dim=args.qk_head_dim,\n",
    "    no_vp=args.no_vp,\n",
    "    init_local_attn=args.init_local_attn,\n",
    "    num_classes=num_classes,\n",
    "    pos_embed=args.pos_embed,\n",
    "    global_pool=args.global_pool,\n",
    "    drop_rate=args.drop_rate,\n",
    "    proj_drop_rate=args.proj_drop_rate,\n",
    "    attn_drop_rate=args.attn_drop_rate,\n",
    ")\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(wiring_lambd=0.0)\n"
     ]
    }
   ],
   "source": [
    "task = ImageClassification(wiring_lambd=args.wiring_lambd)\n",
    "task = task.to(device)\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add encountered 43 time(s)\n",
      "Unsupported operator aten::rsub encountered 1 time(s)\n",
      "Unsupported operator aten::pad encountered 1 time(s)\n",
      "Unsupported operator aten::mul encountered 18 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n",
      "Unsupported operator aten::mean encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 39M, FLOPs: 650M\n"
     ]
    }
   ],
   "source": [
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "flop_count = flops = FlopCountAnalysis(\n",
    "    model, first_batch[\"image\"][:1]\n",
    ").total()\n",
    "\n",
    "print(f\"Params: {param_count / 1e6:.0f}M, FLOPs: {flop_count / 1e6:.0f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.95)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "No decay keys: ['pos_embed', 'patch_embed.proj.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.q.bias', 'encoder.blocks.0.attn.k.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.fc1.bias', 'encoder.blocks.0.mlp.fc2.bias', 'norm.bias', 'head.bias']\n"
     ]
    }
   ],
   "source": [
    "no_decay_keys = ut.get_no_decay_keys(model)\n",
    "optimizer = ut.create_optimizer(\n",
    "    model,\n",
    "    no_decay_keys=no_decay_keys,\n",
    "    lr=args.lr,\n",
    "    weight_decay=args.weight_decay,\n",
    ")\n",
    "epoch_steps = len(loaders[\"train\"])\n",
    "lr_schedule = ut.CosineDecaySchedule(\n",
    "    base_lr=args.lr,\n",
    "    total_steps=args.epochs * epoch_steps,\n",
    "    do_decay=args.decay_lr,\n",
    "    warmup_fraction=args.warmup_fraction,\n",
    ")\n",
    "print(optimizer)\n",
    "print(\"No decay keys:\", no_decay_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    *,\n",
    "    args: Args,\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    task: Task,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    lr_schedule: ut.LRSchedule,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    task.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    is_cuda = device.type == \"cuda\"\n",
    "    if is_cuda:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    loss_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    step_time_m = AverageMeter()\n",
    "    acc_m = AverageMeter()\n",
    "\n",
    "    epoch_batches = len(train_loader)\n",
    "    first_step = epoch * epoch_batches\n",
    "\n",
    "    end = time.monotonic()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        step = first_step + batch_idx\n",
    "        is_last_batch = batch_idx + 1 == epoch_batches\n",
    "        batch_size = len(batch[\"image\"])\n",
    "        data_time = time.monotonic() - end\n",
    "\n",
    "        # forward pass\n",
    "        loss, state = task.forward(model, batch)\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if math.isnan(loss_item) or math.isinf(loss_item):\n",
    "            raise RuntimeError(\"NaN/Inf loss encountered on step %d; exiting\", step)\n",
    "\n",
    "        # update lr\n",
    "        lr = lr_schedule(step)\n",
    "        ut.update_lr_(optimizer, lr)\n",
    "\n",
    "        # backward and optimization step\n",
    "        total_norm = ut.backward_step(loss, optimizer, max_grad_norm=args.clip_grad)\n",
    "\n",
    "        # end of iteration timing\n",
    "        if is_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        step_time = time.monotonic() - end\n",
    "        \n",
    "        loss_m.update(loss_item, batch_size)\n",
    "        data_time_m.update(data_time, batch_size)\n",
    "        step_time_m.update(step_time, batch_size)\n",
    "        \n",
    "        acc_item = accuracy(state)\n",
    "        acc_m.update(acc_item, batch_size)\n",
    "\n",
    "        if step % args.log_interval == 0 or is_last_batch or args.debug:\n",
    "            tput = args.batch_size / step_time_m.avg\n",
    "            if is_cuda:\n",
    "                alloc_mem_gb = torch.cuda.max_memory_allocated() / 1e9\n",
    "                res_mem_gb = torch.cuda.max_memory_reserved() / 1e9\n",
    "            else:\n",
    "                alloc_mem_gb = res_mem_gb = 0.0\n",
    "\n",
    "            print(\n",
    "                f\"Train: {epoch:>3d} [{batch_idx:>3d}/{epoch_batches}][{step:>6d}]\"\n",
    "                f\"  Loss: {loss_m.val:#.3g} ({loss_m.avg:#.3g})\"\n",
    "                f\"  Acc: {acc_m.val:#.3g} ({acc_m.avg:#.3g})\"\n",
    "                f\"  LR: {lr:.3e}\"\n",
    "                f\"  Grad: {total_norm:.3e}\"\n",
    "                f\"  Time: {data_time_m.avg:.3f},{step_time_m.avg:.3f} {tput:.0f}/s\"\n",
    "                f\"  Mem: {alloc_mem_gb:.2f},{res_mem_gb:.2f} GB\"\n",
    "            )\n",
    "\n",
    "        # Restart timer for next iteration\n",
    "        end = time.monotonic()\n",
    "\n",
    "        if args.debug:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(\n",
    "    *,\n",
    "    args: Args,\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    task: Task,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    task.eval()\n",
    "\n",
    "    is_cuda = device.type == \"cuda\"\n",
    "    if is_cuda:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    loss_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    step_time_m = AverageMeter()\n",
    "    acc_m = AverageMeter()\n",
    "\n",
    "    epoch_batches = len(val_loader)\n",
    "    end = time.monotonic()\n",
    "    for batch_idx, batch in enumerate(val_loader):\n",
    "        batch_size = len(batch[\"image\"])\n",
    "        data_time = time.monotonic() - end\n",
    "\n",
    "        loss, state = task.forward(model, batch)\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        # end of iteration timing\n",
    "        if is_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        step_time = time.monotonic() - end\n",
    "\n",
    "        loss_m.update(loss_item, batch_size)\n",
    "        data_time_m.update(data_time, batch_size)\n",
    "        step_time_m.update(step_time, batch_size)\n",
    "        \n",
    "        acc_item = accuracy(state)\n",
    "        acc_m.update(acc_item, batch_size)\n",
    "\n",
    "        if (\n",
    "            batch_idx % args.log_interval == 0\n",
    "            or batch_idx + 1 == epoch_batches\n",
    "            or args.debug\n",
    "        ):\n",
    "            tput = args.batch_size / step_time_m.avg\n",
    "            if is_cuda: \n",
    "                alloc_mem_gb = torch.cuda.max_memory_allocated() / 1e9\n",
    "                res_mem_gb = torch.cuda.max_memory_reserved() / 1e9\n",
    "            else:\n",
    "                alloc_mem_gb = res_mem_gb = 0.0\n",
    "\n",
    "            print(\n",
    "                f\"Val: {epoch:>3d} [{batch_idx:>3d}/{epoch_batches}]\"\n",
    "                f\"  Loss: {loss_m.val:#.3g} ({loss_m.avg:#.3g})\"\n",
    "                f\"  Acc: {acc_m.val:#.3g} ({acc_m.avg:#.3g})\"\n",
    "                f\"  Time: {data_time_m.avg:.3f},{step_time_m.avg:.3f} {tput:.0f}/s\"\n",
    "                f\"  Mem: {alloc_mem_gb:.2f},{res_mem_gb:.2f} GB\"\n",
    "            )\n",
    "\n",
    "        if args.debug:\n",
    "            break\n",
    "\n",
    "        # Reset timer\n",
    "        end = time.monotonic()\n",
    "\n",
    "    return loss_m.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Train:   0 [  0/469][     0]  Loss: 4.72 (4.72)  Acc: 0.781 (0.781)  LR: 1.000e-04  Grad: 2.039e+00  Time: 1.272,1.811 141/s  Mem: 9.57,9.83 GB\n",
      "Train:   0 [ 10/469][    10]  Loss: 4.52 (4.58)  Acc: 1.17 (1.85)  LR: 1.000e-04  Grad: 1.796e+00  Time: 0.162,0.383 668/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 20/469][    20]  Loss: 4.46 (4.54)  Acc: 3.52 (2.40)  LR: 1.000e-04  Grad: 1.645e+00  Time: 0.094,0.298 860/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 30/469][    30]  Loss: 4.49 (4.51)  Acc: 4.30 (2.63)  LR: 1.000e-04  Grad: 1.722e+00  Time: 0.071,0.267 958/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 40/469][    40]  Loss: 4.39 (4.49)  Acc: 4.30 (2.94)  LR: 1.000e-04  Grad: 1.522e+00  Time: 0.058,0.252 1016/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 50/469][    50]  Loss: 4.32 (4.47)  Acc: 5.86 (3.24)  LR: 1.000e-04  Grad: 1.595e+00  Time: 0.051,0.242 1056/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 60/469][    60]  Loss: 4.39 (4.45)  Acc: 4.69 (3.48)  LR: 1.000e-04  Grad: 1.530e+00  Time: 0.046,0.236 1084/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 70/469][    70]  Loss: 4.34 (4.44)  Acc: 3.52 (3.82)  LR: 1.000e-04  Grad: 1.654e+00  Time: 0.042,0.232 1105/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 80/469][    80]  Loss: 4.31 (4.42)  Acc: 5.86 (4.08)  LR: 1.000e-04  Grad: 1.561e+00  Time: 0.040,0.228 1122/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [ 90/469][    90]  Loss: 4.26 (4.40)  Acc: 7.81 (4.38)  LR: 1.000e-04  Grad: 1.427e+00  Time: 0.038,0.226 1135/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [100/469][   100]  Loss: 4.15 (4.39)  Acc: 6.64 (4.63)  LR: 1.000e-04  Grad: 1.501e+00  Time: 0.036,0.224 1145/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [110/469][   110]  Loss: 4.15 (4.37)  Acc: 10.9 (4.92)  LR: 1.000e-04  Grad: 1.690e+00  Time: 0.035,0.222 1154/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [120/469][   120]  Loss: 4.18 (4.35)  Acc: 9.38 (5.19)  LR: 1.000e-04  Grad: 1.646e+00  Time: 0.033,0.220 1162/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [130/469][   130]  Loss: 4.10 (4.33)  Acc: 11.3 (5.53)  LR: 1.000e-04  Grad: 1.715e+00  Time: 0.033,0.219 1167/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [140/469][   140]  Loss: 4.02 (4.31)  Acc: 12.9 (5.91)  LR: 1.000e-04  Grad: 1.842e+00  Time: 0.032,0.218 1172/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [150/469][   150]  Loss: 4.02 (4.29)  Acc: 10.9 (6.24)  LR: 1.000e-04  Grad: 1.933e+00  Time: 0.031,0.218 1177/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [160/469][   160]  Loss: 3.92 (4.27)  Acc: 14.5 (6.67)  LR: 1.000e-04  Grad: 2.014e+00  Time: 0.031,0.217 1181/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [170/469][   170]  Loss: 3.92 (4.25)  Acc: 13.7 (7.18)  LR: 1.000e-04  Grad: 2.164e+00  Time: 0.030,0.216 1185/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [180/469][   180]  Loss: 3.78 (4.22)  Acc: 18.4 (7.76)  LR: 1.000e-04  Grad: 2.302e+00  Time: 0.030,0.216 1188/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [190/469][   190]  Loss: 3.76 (4.20)  Acc: 16.0 (8.25)  LR: 1.000e-04  Grad: 2.361e+00  Time: 0.029,0.215 1191/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [200/469][   200]  Loss: 3.68 (4.17)  Acc: 21.1 (8.83)  LR: 1.000e-04  Grad: 2.190e+00  Time: 0.029,0.214 1194/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [210/469][   210]  Loss: 3.55 (4.15)  Acc: 24.2 (9.45)  LR: 1.000e-04  Grad: 2.485e+00  Time: 0.029,0.214 1196/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [220/469][   220]  Loss: 3.46 (4.12)  Acc: 22.3 (10.1)  LR: 1.000e-04  Grad: 2.512e+00  Time: 0.028,0.214 1198/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [230/469][   230]  Loss: 3.51 (4.09)  Acc: 25.4 (10.7)  LR: 1.000e-04  Grad: 2.757e+00  Time: 0.028,0.213 1200/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [240/469][   240]  Loss: 3.35 (4.07)  Acc: 28.9 (11.4)  LR: 1.000e-04  Grad: 2.536e+00  Time: 0.028,0.213 1202/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [250/469][   250]  Loss: 3.21 (4.04)  Acc: 36.7 (12.1)  LR: 1.000e-04  Grad: 2.820e+00  Time: 0.028,0.213 1203/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [260/469][   260]  Loss: 3.23 (4.01)  Acc: 32.0 (12.8)  LR: 1.000e-04  Grad: 3.187e+00  Time: 0.027,0.213 1205/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [270/469][   270]  Loss: 3.23 (3.98)  Acc: 34.0 (13.6)  LR: 1.000e-04  Grad: 3.715e+00  Time: 0.027,0.212 1206/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [280/469][   280]  Loss: 3.03 (3.95)  Acc: 39.1 (14.4)  LR: 1.000e-04  Grad: 3.229e+00  Time: 0.027,0.212 1207/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [290/469][   290]  Loss: 3.01 (3.92)  Acc: 37.1 (15.1)  LR: 1.000e-04  Grad: 3.496e+00  Time: 0.027,0.212 1209/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [300/469][   300]  Loss: 2.97 (3.89)  Acc: 41.0 (15.9)  LR: 1.000e-04  Grad: 3.567e+00  Time: 0.027,0.212 1210/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [310/469][   310]  Loss: 2.95 (3.86)  Acc: 39.5 (16.7)  LR: 1.000e-04  Grad: 3.907e+00  Time: 0.026,0.211 1211/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [320/469][   320]  Loss: 2.76 (3.83)  Acc: 48.0 (17.5)  LR: 1.000e-04  Grad: 3.643e+00  Time: 0.026,0.211 1212/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [330/469][   330]  Loss: 2.85 (3.80)  Acc: 38.3 (18.3)  LR: 1.000e-04  Grad: 3.739e+00  Time: 0.026,0.211 1213/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [340/469][   340]  Loss: 2.71 (3.76)  Acc: 46.5 (19.2)  LR: 1.000e-04  Grad: 3.624e+00  Time: 0.026,0.211 1214/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [350/469][   350]  Loss: 2.56 (3.73)  Acc: 50.8 (20.0)  LR: 1.000e-04  Grad: 3.713e+00  Time: 0.026,0.211 1215/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [360/469][   360]  Loss: 2.49 (3.70)  Acc: 53.1 (20.9)  LR: 1.000e-04  Grad: 4.244e+00  Time: 0.026,0.211 1215/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [370/469][   370]  Loss: 2.40 (3.67)  Acc: 57.0 (21.8)  LR: 1.000e-04  Grad: 4.228e+00  Time: 0.026,0.211 1216/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [380/469][   380]  Loss: 2.44 (3.64)  Acc: 51.6 (22.6)  LR: 1.000e-04  Grad: 5.498e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [390/469][   390]  Loss: 2.42 (3.60)  Acc: 52.0 (23.5)  LR: 1.000e-04  Grad: 4.670e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [400/469][   400]  Loss: 2.33 (3.57)  Acc: 54.7 (24.3)  LR: 1.000e-04  Grad: 4.931e+00  Time: 0.025,0.210 1218/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [410/469][   410]  Loss: 2.07 (3.54)  Acc: 66.0 (25.2)  LR: 1.000e-04  Grad: 4.951e+00  Time: 0.025,0.210 1219/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [420/469][   420]  Loss: 2.13 (3.50)  Acc: 61.7 (26.1)  LR: 1.000e-04  Grad: 4.292e+00  Time: 0.025,0.210 1219/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [430/469][   430]  Loss: 2.01 (3.47)  Acc: 68.4 (26.9)  LR: 1.000e-04  Grad: 4.834e+00  Time: 0.025,0.210 1220/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [440/469][   440]  Loss: 1.96 (3.44)  Acc: 65.6 (27.8)  LR: 1.000e-04  Grad: 5.146e+00  Time: 0.025,0.210 1220/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [450/469][   450]  Loss: 1.96 (3.40)  Acc: 59.8 (28.6)  LR: 1.000e-04  Grad: 4.487e+00  Time: 0.025,0.210 1221/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [460/469][   460]  Loss: 1.76 (3.37)  Acc: 71.9 (29.5)  LR: 1.000e-04  Grad: 4.929e+00  Time: 0.025,0.210 1221/s  Mem: 11.57,11.84 GB\n",
      "Train:   0 [468/469][   468]  Loss: 1.68 (3.34)  Acc: 73.4 (30.1)  LR: 1.000e-04  Grad: 4.838e+00  Time: 0.025,0.210 1222/s  Mem: 11.57,11.84 GB\n",
      "Val:   0 [  0/20]  Loss: 4.80 (4.80)  Acc: 3.52 (3.52)  Time: 0.954,1.023 250/s  Mem: 3.53,11.94 GB\n",
      "Val:   0 [ 10/20]  Loss: 4.78 (4.72)  Acc: 5.08 (4.65)  Time: 0.150,0.219 1167/s  Mem: 5.39,11.99 GB\n",
      "Val:   0 [ 19/20]  Loss: 4.39 (4.71)  Acc: 5.88 (4.30)  Time: 0.116,0.184 1388/s  Mem: 5.39,11.99 GB\n",
      "Starting epoch 1\n",
      "Train:   1 [  1/469][   470]  Loss: 1.65 (1.74)  Acc: 73.8 (71.3)  LR: 1.000e-04  Grad: 3.924e+00  Time: 0.501,0.685 374/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 11/469][   480]  Loss: 1.63 (1.68)  Acc: 74.2 (71.8)  LR: 1.000e-04  Grad: 5.032e+00  Time: 0.101,0.285 898/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 21/469][   490]  Loss: 1.54 (1.64)  Acc: 73.0 (72.6)  LR: 1.000e-04  Grad: 6.639e+00  Time: 0.065,0.249 1029/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 31/469][   500]  Loss: 1.52 (1.63)  Acc: 77.7 (72.6)  LR: 1.000e-04  Grad: 4.637e+00  Time: 0.051,0.235 1089/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 41/469][   510]  Loss: 1.57 (1.60)  Acc: 71.1 (73.0)  LR: 1.000e-04  Grad: 6.012e+00  Time: 0.044,0.228 1123/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 51/469][   520]  Loss: 1.48 (1.57)  Acc: 76.6 (73.7)  LR: 1.000e-04  Grad: 5.117e+00  Time: 0.040,0.224 1145/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 61/469][   530]  Loss: 1.33 (1.54)  Acc: 79.7 (74.4)  LR: 1.000e-04  Grad: 4.313e+00  Time: 0.037,0.221 1161/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 71/469][   540]  Loss: 1.19 (1.51)  Acc: 82.4 (74.9)  LR: 1.000e-04  Grad: 6.429e+00  Time: 0.035,0.218 1172/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 81/469][   550]  Loss: 1.33 (1.49)  Acc: 76.6 (75.3)  LR: 1.000e-04  Grad: 6.164e+00  Time: 0.033,0.217 1181/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [ 91/469][   560]  Loss: 1.27 (1.46)  Acc: 77.3 (76.0)  LR: 1.000e-04  Grad: 4.984e+00  Time: 0.032,0.216 1188/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [101/469][   570]  Loss: 1.15 (1.43)  Acc: 83.2 (76.3)  LR: 1.000e-04  Grad: 5.831e+00  Time: 0.031,0.215 1193/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [111/469][   580]  Loss: 1.32 (1.41)  Acc: 77.7 (76.8)  LR: 1.000e-04  Grad: 5.785e+00  Time: 0.030,0.214 1198/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [121/469][   590]  Loss: 1.06 (1.39)  Acc: 83.6 (77.3)  LR: 1.000e-04  Grad: 5.470e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [131/469][   600]  Loss: 1.04 (1.36)  Acc: 82.0 (77.8)  LR: 1.000e-04  Grad: 4.590e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [141/469][   610]  Loss: 0.993 (1.34)  Acc: 83.2 (78.2)  LR: 1.000e-04  Grad: 5.795e+00  Time: 0.028,0.212 1207/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [151/469][   620]  Loss: 1.01 (1.31)  Acc: 83.6 (78.6)  LR: 1.000e-04  Grad: 5.831e+00  Time: 0.028,0.212 1210/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [161/469][   630]  Loss: 0.995 (1.29)  Acc: 84.4 (79.0)  LR: 1.000e-04  Grad: 7.505e+00  Time: 0.027,0.211 1212/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [171/469][   640]  Loss: 0.897 (1.27)  Acc: 84.8 (79.4)  LR: 1.000e-04  Grad: 5.024e+00  Time: 0.027,0.211 1214/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [181/469][   650]  Loss: 0.750 (1.24)  Acc: 90.6 (79.9)  LR: 1.000e-04  Grad: 4.981e+00  Time: 0.027,0.211 1216/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [191/469][   660]  Loss: 0.800 (1.22)  Acc: 88.3 (80.2)  LR: 1.000e-04  Grad: 5.320e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [201/469][   670]  Loss: 0.687 (1.20)  Acc: 89.5 (80.7)  LR: 1.000e-04  Grad: 4.994e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [211/469][   680]  Loss: 0.765 (1.18)  Acc: 88.3 (81.0)  LR: 1.000e-04  Grad: 5.966e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [221/469][   690]  Loss: 0.749 (1.16)  Acc: 86.3 (81.3)  LR: 1.000e-04  Grad: 4.931e+00  Time: 0.026,0.210 1221/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [231/469][   700]  Loss: 0.778 (1.14)  Acc: 89.1 (81.6)  LR: 1.000e-04  Grad: 5.583e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [241/469][   710]  Loss: 0.623 (1.12)  Acc: 89.1 (81.9)  LR: 1.000e-04  Grad: 6.053e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [251/469][   720]  Loss: 0.598 (1.10)  Acc: 92.2 (82.2)  LR: 1.000e-04  Grad: 7.922e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [261/469][   730]  Loss: 0.623 (1.08)  Acc: 90.6 (82.5)  LR: 1.000e-04  Grad: 4.754e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [271/469][   740]  Loss: 0.677 (1.07)  Acc: 89.1 (82.8)  LR: 1.000e-04  Grad: 6.255e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [281/469][   750]  Loss: 0.619 (1.05)  Acc: 89.1 (83.0)  LR: 1.000e-04  Grad: 5.617e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [291/469][   760]  Loss: 0.647 (1.04)  Acc: 87.9 (83.3)  LR: 1.000e-04  Grad: 6.421e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [301/469][   770]  Loss: 0.608 (1.02)  Acc: 88.7 (83.5)  LR: 1.000e-04  Grad: 5.009e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [311/469][   780]  Loss: 0.505 (1.01)  Acc: 92.6 (83.8)  LR: 1.000e-04  Grad: 5.155e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [321/469][   790]  Loss: 0.553 (0.989)  Acc: 92.2 (84.0)  LR: 1.000e-04  Grad: 4.402e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [331/469][   800]  Loss: 0.452 (0.974)  Acc: 91.8 (84.3)  LR: 1.000e-04  Grad: 4.781e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [341/469][   810]  Loss: 0.488 (0.959)  Acc: 92.2 (84.5)  LR: 1.000e-04  Grad: 5.725e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [351/469][   820]  Loss: 0.494 (0.944)  Acc: 92.2 (84.7)  LR: 1.000e-04  Grad: 6.496e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [361/469][   830]  Loss: 0.445 (0.930)  Acc: 91.4 (85.0)  LR: 1.000e-04  Grad: 6.475e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [371/469][   840]  Loss: 0.397 (0.917)  Acc: 93.0 (85.2)  LR: 1.000e-04  Grad: 6.503e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [381/469][   850]  Loss: 0.394 (0.904)  Acc: 93.4 (85.4)  LR: 1.000e-04  Grad: 5.087e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [391/469][   860]  Loss: 0.347 (0.891)  Acc: 94.1 (85.6)  LR: 1.000e-04  Grad: 3.655e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [401/469][   870]  Loss: 0.370 (0.879)  Acc: 95.7 (85.8)  LR: 1.000e-04  Grad: 5.691e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [411/469][   880]  Loss: 0.362 (0.867)  Acc: 93.4 (86.0)  LR: 1.000e-04  Grad: 4.728e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [421/469][   890]  Loss: 0.312 (0.854)  Acc: 94.9 (86.1)  LR: 1.000e-04  Grad: 3.698e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [431/469][   900]  Loss: 0.367 (0.843)  Acc: 92.6 (86.3)  LR: 1.000e-04  Grad: 4.963e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [441/469][   910]  Loss: 0.440 (0.832)  Acc: 90.2 (86.5)  LR: 1.000e-04  Grad: 5.528e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [451/469][   920]  Loss: 0.406 (0.821)  Acc: 93.4 (86.6)  LR: 1.000e-04  Grad: 4.816e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [461/469][   930]  Loss: 0.342 (0.811)  Acc: 95.3 (86.8)  LR: 1.000e-04  Grad: 6.276e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.15 GB\n",
      "Train:   1 [468/469][   937]  Loss: 0.442 (0.804)  Acc: 90.6 (86.9)  LR: 1.000e-04  Grad: 6.725e+00  Time: 0.024,0.208 1234/s  Mem: 11.57,12.15 GB\n",
      "Val:   1 [  0/20]  Loss: 5.54 (5.54)  Acc: 5.86 (5.86)  Time: 1.007,1.076 238/s  Mem: 3.53,12.25 GB\n",
      "Val:   1 [ 10/20]  Loss: 5.64 (5.53)  Acc: 3.12 (4.62)  Time: 0.153,0.223 1150/s  Mem: 5.39,12.30 GB\n",
      "Val:   1 [ 19/20]  Loss: 5.90 (5.54)  Acc: 2.21 (4.16)  Time: 0.118,0.187 1372/s  Mem: 5.39,12.30 GB\n",
      "Starting epoch 2\n",
      "Train:   2 [  2/469][   940]  Loss: 0.301 (0.322)  Acc: 93.8 (94.3)  LR: 1.000e-04  Grad: 3.900e+00  Time: 0.339,0.522 490/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 12/469][   950]  Loss: 0.280 (0.307)  Acc: 94.5 (94.8)  LR: 1.000e-04  Grad: 5.343e+00  Time: 0.095,0.278 919/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 22/469][   960]  Loss: 0.246 (0.302)  Acc: 94.9 (94.7)  LR: 1.000e-04  Grad: 5.337e+00  Time: 0.063,0.247 1038/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 32/469][   970]  Loss: 0.323 (0.298)  Acc: 94.5 (94.8)  LR: 1.000e-04  Grad: 6.175e+00  Time: 0.050,0.234 1094/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 42/469][   980]  Loss: 0.275 (0.297)  Acc: 94.5 (94.8)  LR: 1.000e-04  Grad: 4.729e+00  Time: 0.043,0.227 1126/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 52/469][   990]  Loss: 0.314 (0.297)  Acc: 93.4 (94.7)  LR: 1.000e-04  Grad: 5.762e+00  Time: 0.039,0.223 1147/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 62/469][  1000]  Loss: 0.357 (0.297)  Acc: 93.0 (94.6)  LR: 1.000e-04  Grad: 7.081e+00  Time: 0.036,0.220 1162/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 72/469][  1010]  Loss: 0.245 (0.293)  Acc: 95.7 (94.7)  LR: 1.000e-04  Grad: 6.010e+00  Time: 0.034,0.218 1173/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 82/469][  1020]  Loss: 0.208 (0.288)  Acc: 96.5 (94.8)  LR: 1.000e-04  Grad: 4.711e+00  Time: 0.033,0.217 1182/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [ 92/469][  1030]  Loss: 0.260 (0.287)  Acc: 95.7 (94.8)  LR: 1.000e-04  Grad: 6.460e+00  Time: 0.031,0.215 1188/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [102/469][  1040]  Loss: 0.262 (0.285)  Acc: 95.3 (94.8)  LR: 1.000e-04  Grad: 4.768e+00  Time: 0.030,0.214 1194/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [112/469][  1050]  Loss: 0.380 (0.282)  Acc: 91.8 (94.8)  LR: 1.000e-04  Grad: 4.894e+00  Time: 0.030,0.214 1198/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [122/469][  1060]  Loss: 0.214 (0.279)  Acc: 95.7 (94.9)  LR: 1.000e-04  Grad: 5.617e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [132/469][  1070]  Loss: 0.205 (0.276)  Acc: 96.5 (94.9)  LR: 1.000e-04  Grad: 4.278e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [142/469][  1080]  Loss: 0.271 (0.274)  Acc: 95.3 (94.9)  LR: 1.000e-04  Grad: 5.759e+00  Time: 0.028,0.212 1208/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [152/469][  1090]  Loss: 0.238 (0.274)  Acc: 96.9 (95.0)  LR: 1.000e-04  Grad: 4.317e+00  Time: 0.027,0.211 1211/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [162/469][  1100]  Loss: 0.227 (0.271)  Acc: 96.1 (95.0)  LR: 1.000e-04  Grad: 6.167e+00  Time: 0.027,0.211 1212/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [172/469][  1110]  Loss: 0.213 (0.268)  Acc: 95.7 (95.1)  LR: 1.000e-04  Grad: 6.601e+00  Time: 0.027,0.211 1214/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [182/469][  1120]  Loss: 0.247 (0.265)  Acc: 96.1 (95.1)  LR: 1.000e-04  Grad: 3.862e+00  Time: 0.027,0.210 1216/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [192/469][  1130]  Loss: 0.353 (0.264)  Acc: 92.6 (95.1)  LR: 1.000e-04  Grad: 6.188e+00  Time: 0.026,0.210 1218/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [202/469][  1140]  Loss: 0.180 (0.262)  Acc: 96.1 (95.1)  LR: 1.000e-04  Grad: 3.957e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [212/469][  1150]  Loss: 0.198 (0.259)  Acc: 96.1 (95.2)  LR: 1.000e-04  Grad: 4.509e+00  Time: 0.026,0.210 1221/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [222/469][  1160]  Loss: 0.166 (0.256)  Acc: 97.3 (95.2)  LR: 1.000e-04  Grad: 1.027e+01  Time: 0.026,0.210 1222/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [232/469][  1170]  Loss: 0.201 (0.254)  Acc: 96.1 (95.3)  LR: 1.000e-04  Grad: 3.726e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [242/469][  1180]  Loss: 0.258 (0.252)  Acc: 94.9 (95.3)  LR: 1.000e-04  Grad: 6.093e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [252/469][  1190]  Loss: 0.244 (0.251)  Acc: 94.5 (95.3)  LR: 1.000e-04  Grad: 5.536e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [262/469][  1200]  Loss: 0.175 (0.249)  Acc: 95.7 (95.3)  LR: 1.000e-04  Grad: 6.424e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [272/469][  1210]  Loss: 0.214 (0.248)  Acc: 95.3 (95.3)  LR: 1.000e-04  Grad: 3.798e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [282/469][  1220]  Loss: 0.183 (0.246)  Acc: 96.5 (95.3)  LR: 1.000e-04  Grad: 6.166e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [292/469][  1230]  Loss: 0.175 (0.244)  Acc: 97.3 (95.4)  LR: 1.000e-04  Grad: 4.149e+00  Time: 0.025,0.209 1228/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [302/469][  1240]  Loss: 0.227 (0.242)  Acc: 95.7 (95.4)  LR: 1.000e-04  Grad: 5.056e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [312/469][  1250]  Loss: 0.129 (0.241)  Acc: 98.0 (95.4)  LR: 1.000e-04  Grad: 4.325e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [322/469][  1260]  Loss: 0.152 (0.239)  Acc: 97.7 (95.5)  LR: 1.000e-04  Grad: 3.882e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [332/469][  1270]  Loss: 0.222 (0.238)  Acc: 94.9 (95.5)  LR: 1.000e-04  Grad: 4.675e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [342/469][  1280]  Loss: 0.159 (0.236)  Acc: 96.5 (95.5)  LR: 1.000e-04  Grad: 3.051e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [352/469][  1290]  Loss: 0.161 (0.235)  Acc: 95.3 (95.5)  LR: 1.000e-04  Grad: 4.812e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [362/469][  1300]  Loss: 0.194 (0.233)  Acc: 96.5 (95.5)  LR: 1.000e-04  Grad: 4.636e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [372/469][  1310]  Loss: 0.188 (0.232)  Acc: 95.7 (95.5)  LR: 1.000e-04  Grad: 4.939e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [382/469][  1320]  Loss: 0.302 (0.230)  Acc: 92.6 (95.5)  LR: 1.000e-04  Grad: 8.644e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [392/469][  1330]  Loss: 0.140 (0.229)  Acc: 98.0 (95.6)  LR: 1.000e-04  Grad: 3.787e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [402/469][  1340]  Loss: 0.189 (0.227)  Acc: 95.7 (95.6)  LR: 1.000e-04  Grad: 3.618e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [412/469][  1350]  Loss: 0.159 (0.227)  Acc: 96.5 (95.6)  LR: 1.000e-04  Grad: 4.422e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [422/469][  1360]  Loss: 0.145 (0.225)  Acc: 97.3 (95.6)  LR: 1.000e-04  Grad: 3.442e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [432/469][  1370]  Loss: 0.127 (0.224)  Acc: 97.3 (95.6)  LR: 1.000e-04  Grad: 5.593e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [442/469][  1380]  Loss: 0.116 (0.223)  Acc: 98.0 (95.6)  LR: 1.000e-04  Grad: 4.960e+00  Time: 0.024,0.208 1234/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [452/469][  1390]  Loss: 0.156 (0.221)  Acc: 95.7 (95.7)  LR: 1.000e-04  Grad: 5.067e+00  Time: 0.024,0.207 1234/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [462/469][  1400]  Loss: 0.145 (0.220)  Acc: 97.3 (95.7)  LR: 1.000e-04  Grad: 4.244e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,12.45 GB\n",
      "Train:   2 [468/469][  1406]  Loss: 0.0879 (0.219)  Acc: 99.0 (95.7)  LR: 1.000e-04  Grad: 3.008e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,12.45 GB\n",
      "Val:   2 [  0/20]  Loss: 6.20 (6.20)  Acc: 1.95 (1.95)  Time: 0.974,1.044 245/s  Mem: 3.53,12.56 GB\n",
      "Val:   2 [ 10/20]  Loss: 6.08 (6.09)  Acc: 2.73 (3.16)  Time: 0.154,0.224 1145/s  Mem: 5.39,12.61 GB\n",
      "Val:   2 [ 19/20]  Loss: 6.20 (6.12)  Acc: 3.68 (3.26)  Time: 0.119,0.187 1366/s  Mem: 5.39,12.61 GB\n",
      "Starting epoch 3\n",
      "Train:   3 [  3/469][  1410]  Loss: 0.201 (0.169)  Acc: 95.3 (96.5)  LR: 1.000e-04  Grad: 5.089e+00  Time: 0.259,0.443 578/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 13/469][  1420]  Loss: 0.105 (0.137)  Acc: 97.7 (97.3)  LR: 1.000e-04  Grad: 4.514e+00  Time: 0.090,0.273 936/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 23/469][  1430]  Loss: 0.186 (0.149)  Acc: 95.3 (96.9)  LR: 1.000e-04  Grad: 4.052e+00  Time: 0.062,0.245 1043/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 33/469][  1440]  Loss: 0.118 (0.149)  Acc: 96.5 (96.9)  LR: 1.000e-04  Grad: 3.116e+00  Time: 0.050,0.234 1096/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 43/469][  1450]  Loss: 0.148 (0.145)  Acc: 96.5 (97.1)  LR: 1.000e-04  Grad: 6.312e+00  Time: 0.043,0.227 1127/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 53/469][  1460]  Loss: 0.173 (0.146)  Acc: 96.5 (97.0)  LR: 1.000e-04  Grad: 4.760e+00  Time: 0.039,0.223 1147/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 63/469][  1470]  Loss: 0.153 (0.153)  Acc: 95.3 (96.9)  LR: 1.000e-04  Grad: 4.554e+00  Time: 0.036,0.220 1162/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 73/469][  1480]  Loss: 0.117 (0.151)  Acc: 98.0 (96.9)  LR: 1.000e-04  Grad: 3.408e+00  Time: 0.034,0.218 1173/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 83/469][  1490]  Loss: 0.163 (0.149)  Acc: 97.3 (96.9)  LR: 1.000e-04  Grad: 4.012e+00  Time: 0.033,0.217 1181/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [ 93/469][  1500]  Loss: 0.150 (0.148)  Acc: 97.7 (96.9)  LR: 1.000e-04  Grad: 7.583e+00  Time: 0.032,0.215 1188/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [103/469][  1510]  Loss: 0.152 (0.149)  Acc: 96.9 (96.9)  LR: 1.000e-04  Grad: 5.029e+00  Time: 0.031,0.214 1194/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [113/469][  1520]  Loss: 0.193 (0.150)  Acc: 96.9 (96.9)  LR: 1.000e-04  Grad: 3.995e+00  Time: 0.030,0.214 1198/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [123/469][  1530]  Loss: 0.109 (0.149)  Acc: 98.0 (96.9)  LR: 1.000e-04  Grad: 2.239e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [133/469][  1540]  Loss: 0.0928 (0.147)  Acc: 97.3 (97.0)  LR: 1.000e-04  Grad: 6.583e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [143/469][  1550]  Loss: 0.151 (0.147)  Acc: 97.3 (97.0)  LR: 1.000e-04  Grad: 3.999e+00  Time: 0.028,0.212 1208/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [153/469][  1560]  Loss: 0.155 (0.147)  Acc: 96.9 (97.0)  LR: 1.000e-04  Grad: 3.178e+00  Time: 0.028,0.211 1211/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [163/469][  1570]  Loss: 0.0974 (0.147)  Acc: 98.4 (97.0)  LR: 1.000e-04  Grad: 3.389e+00  Time: 0.027,0.211 1213/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [173/469][  1580]  Loss: 0.147 (0.146)  Acc: 97.3 (97.0)  LR: 1.000e-04  Grad: 3.292e+00  Time: 0.027,0.211 1215/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [183/469][  1590]  Loss: 0.109 (0.145)  Acc: 98.0 (97.0)  LR: 1.000e-04  Grad: 2.634e+00  Time: 0.027,0.210 1216/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [193/469][  1600]  Loss: 0.120 (0.144)  Acc: 97.3 (97.0)  LR: 1.000e-04  Grad: 4.196e+00  Time: 0.026,0.210 1218/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [203/469][  1610]  Loss: 0.0936 (0.143)  Acc: 98.4 (97.1)  LR: 1.000e-04  Grad: 2.345e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [213/469][  1620]  Loss: 0.201 (0.143)  Acc: 96.1 (97.0)  LR: 1.000e-04  Grad: 8.019e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [223/469][  1630]  Loss: 0.188 (0.144)  Acc: 96.1 (97.0)  LR: 1.000e-04  Grad: 3.226e+00  Time: 0.026,0.210 1222/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [233/469][  1640]  Loss: 0.0685 (0.144)  Acc: 98.8 (97.0)  LR: 1.000e-04  Grad: 4.172e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [243/469][  1650]  Loss: 0.141 (0.143)  Acc: 96.9 (97.0)  LR: 1.000e-04  Grad: 4.223e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [253/469][  1660]  Loss: 0.147 (0.143)  Acc: 96.9 (97.0)  LR: 1.000e-04  Grad: 5.653e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [263/469][  1670]  Loss: 0.143 (0.142)  Acc: 98.4 (97.1)  LR: 1.000e-04  Grad: 4.382e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [273/469][  1680]  Loss: 0.0609 (0.140)  Acc: 98.8 (97.1)  LR: 1.000e-04  Grad: 2.826e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [283/469][  1690]  Loss: 0.0919 (0.140)  Acc: 98.0 (97.1)  LR: 1.000e-04  Grad: 3.516e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [293/469][  1700]  Loss: 0.158 (0.139)  Acc: 97.3 (97.1)  LR: 1.000e-04  Grad: 3.709e+00  Time: 0.025,0.209 1228/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [303/469][  1710]  Loss: 0.0908 (0.139)  Acc: 98.4 (97.1)  LR: 1.000e-04  Grad: 3.882e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [313/469][  1720]  Loss: 0.121 (0.139)  Acc: 97.7 (97.1)  LR: 1.000e-04  Grad: 4.931e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [323/469][  1730]  Loss: 0.0698 (0.139)  Acc: 98.4 (97.1)  LR: 1.000e-04  Grad: 5.467e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [333/469][  1740]  Loss: 0.0889 (0.138)  Acc: 98.4 (97.1)  LR: 1.000e-04  Grad: 4.119e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [343/469][  1750]  Loss: 0.0830 (0.138)  Acc: 98.4 (97.1)  LR: 1.000e-04  Grad: 2.889e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [353/469][  1760]  Loss: 0.121 (0.137)  Acc: 97.3 (97.1)  LR: 1.000e-04  Grad: 5.587e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [363/469][  1770]  Loss: 0.122 (0.137)  Acc: 98.0 (97.1)  LR: 1.000e-04  Grad: 3.463e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [373/469][  1780]  Loss: 0.0833 (0.136)  Acc: 98.4 (97.2)  LR: 1.000e-04  Grad: 2.058e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [383/469][  1790]  Loss: 0.143 (0.136)  Acc: 97.7 (97.2)  LR: 1.000e-04  Grad: 8.786e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [393/469][  1800]  Loss: 0.0692 (0.135)  Acc: 98.0 (97.2)  LR: 1.000e-04  Grad: 2.461e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [403/469][  1810]  Loss: 0.0668 (0.134)  Acc: 99.2 (97.2)  LR: 1.000e-04  Grad: 2.976e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [413/469][  1820]  Loss: 0.199 (0.133)  Acc: 96.9 (97.2)  LR: 1.000e-04  Grad: 5.655e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [423/469][  1830]  Loss: 0.0717 (0.133)  Acc: 98.8 (97.2)  LR: 1.000e-04  Grad: 3.572e+00  Time: 0.024,0.207 1234/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [433/469][  1840]  Loss: 0.110 (0.132)  Acc: 98.4 (97.2)  LR: 1.000e-04  Grad: 1.037e+01  Time: 0.023,0.207 1234/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [443/469][  1850]  Loss: 0.0914 (0.132)  Acc: 98.8 (97.2)  LR: 1.000e-04  Grad: 3.102e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [453/469][  1860]  Loss: 0.0599 (0.131)  Acc: 99.2 (97.2)  LR: 1.000e-04  Grad: 2.034e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [463/469][  1870]  Loss: 0.117 (0.131)  Acc: 96.9 (97.3)  LR: 1.000e-04  Grad: 3.695e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,12.76 GB\n",
      "Train:   3 [468/469][  1875]  Loss: 0.163 (0.130)  Acc: 96.4 (97.3)  LR: 1.000e-04  Grad: 4.988e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,12.76 GB\n",
      "Val:   3 [  0/20]  Loss: 6.40 (6.40)  Acc: 4.69 (4.69)  Time: 0.983,1.053 243/s  Mem: 3.53,12.86 GB\n",
      "Val:   3 [ 10/20]  Loss: 6.23 (6.34)  Acc: 2.34 (3.73)  Time: 0.154,0.223 1146/s  Mem: 5.39,12.91 GB\n",
      "Val:   3 [ 19/20]  Loss: 6.77 (6.34)  Acc: 2.21 (3.62)  Time: 0.118,0.187 1370/s  Mem: 5.39,12.91 GB\n",
      "Starting epoch 4\n",
      "Train:   4 [  4/469][  1880]  Loss: 0.118 (0.102)  Acc: 96.9 (97.6)  LR: 1.000e-04  Grad: 4.665e+00  Time: 0.209,0.393 652/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 14/469][  1890]  Loss: 0.0833 (0.102)  Acc: 97.7 (97.6)  LR: 1.000e-04  Grad: 5.123e+00  Time: 0.084,0.268 957/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 24/469][  1900]  Loss: 0.115 (0.112)  Acc: 96.9 (97.6)  LR: 1.000e-04  Grad: 4.345e+00  Time: 0.059,0.243 1055/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 34/469][  1910]  Loss: 0.0740 (0.113)  Acc: 98.8 (97.6)  LR: 1.000e-04  Grad: 2.827e+00  Time: 0.048,0.232 1105/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 44/469][  1920]  Loss: 0.136 (0.117)  Acc: 96.9 (97.5)  LR: 1.000e-04  Grad: 3.082e+00  Time: 0.042,0.226 1134/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 54/469][  1930]  Loss: 0.0944 (0.118)  Acc: 97.7 (97.5)  LR: 1.000e-04  Grad: 4.974e+00  Time: 0.038,0.222 1153/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 64/469][  1940]  Loss: 0.0913 (0.118)  Acc: 97.7 (97.5)  LR: 1.000e-04  Grad: 3.357e+00  Time: 0.035,0.219 1167/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 74/469][  1950]  Loss: 0.0705 (0.116)  Acc: 98.8 (97.5)  LR: 1.000e-04  Grad: 1.792e+00  Time: 0.033,0.217 1178/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 84/469][  1960]  Loss: 0.109 (0.113)  Acc: 96.5 (97.6)  LR: 1.000e-04  Grad: 5.095e+00  Time: 0.032,0.216 1186/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [ 94/469][  1970]  Loss: 0.193 (0.114)  Acc: 96.9 (97.5)  LR: 1.000e-04  Grad: 3.894e+00  Time: 0.031,0.215 1192/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [104/469][  1980]  Loss: 0.0829 (0.112)  Acc: 98.0 (97.6)  LR: 1.000e-04  Grad: 2.923e+00  Time: 0.030,0.214 1198/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [114/469][  1990]  Loss: 0.111 (0.112)  Acc: 97.7 (97.6)  LR: 1.000e-04  Grad: 3.898e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [124/469][  2000]  Loss: 0.104 (0.110)  Acc: 98.0 (97.6)  LR: 1.000e-04  Grad: 6.181e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [134/469][  2010]  Loss: 0.0835 (0.108)  Acc: 98.4 (97.7)  LR: 1.000e-04  Grad: 3.245e+00  Time: 0.028,0.212 1209/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [144/469][  2020]  Loss: 0.0701 (0.108)  Acc: 98.0 (97.7)  LR: 1.000e-04  Grad: 2.937e+00  Time: 0.027,0.211 1211/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [154/469][  2030]  Loss: 0.119 (0.108)  Acc: 96.9 (97.7)  LR: 1.000e-04  Grad: 3.622e+00  Time: 0.027,0.211 1214/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [164/469][  2040]  Loss: 0.101 (0.109)  Acc: 98.4 (97.7)  LR: 1.000e-04  Grad: 3.179e+00  Time: 0.027,0.211 1215/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [174/469][  2050]  Loss: 0.0640 (0.108)  Acc: 98.4 (97.7)  LR: 1.000e-04  Grad: 3.471e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [184/469][  2060]  Loss: 0.0895 (0.108)  Acc: 97.7 (97.7)  LR: 1.000e-04  Grad: 2.684e+00  Time: 0.026,0.210 1218/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [194/469][  2070]  Loss: 0.101 (0.107)  Acc: 98.0 (97.7)  LR: 1.000e-04  Grad: 3.958e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [204/469][  2080]  Loss: 0.0879 (0.105)  Acc: 98.8 (97.7)  LR: 1.000e-04  Grad: 3.071e+00  Time: 0.026,0.210 1221/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [214/469][  2090]  Loss: 0.150 (0.106)  Acc: 96.5 (97.7)  LR: 1.000e-04  Grad: 6.667e+00  Time: 0.025,0.209 1222/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [224/469][  2100]  Loss: 0.131 (0.105)  Acc: 96.9 (97.7)  LR: 1.000e-04  Grad: 4.648e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [234/469][  2110]  Loss: 0.114 (0.105)  Acc: 98.4 (97.8)  LR: 1.000e-04  Grad: 5.486e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [244/469][  2120]  Loss: 0.0839 (0.104)  Acc: 97.3 (97.8)  LR: 1.000e-04  Grad: 4.856e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [254/469][  2130]  Loss: 0.173 (0.104)  Acc: 97.3 (97.8)  LR: 1.000e-04  Grad: 3.358e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [264/469][  2140]  Loss: 0.105 (0.104)  Acc: 97.7 (97.8)  LR: 1.000e-04  Grad: 3.157e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [274/469][  2150]  Loss: 0.0688 (0.104)  Acc: 98.4 (97.8)  LR: 1.000e-04  Grad: 2.382e+01  Time: 0.024,0.208 1229/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [284/469][  2160]  Loss: 0.0884 (0.103)  Acc: 97.3 (97.8)  LR: 1.000e-04  Grad: 6.000e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [294/469][  2170]  Loss: 0.0854 (0.103)  Acc: 98.0 (97.8)  LR: 1.000e-04  Grad: 4.999e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [304/469][  2180]  Loss: 0.152 (0.104)  Acc: 97.3 (97.8)  LR: 1.000e-04  Grad: 6.390e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [314/469][  2190]  Loss: 0.115 (0.103)  Acc: 98.4 (97.8)  LR: 1.000e-04  Grad: 4.225e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [324/469][  2200]  Loss: 0.0831 (0.103)  Acc: 97.3 (97.8)  LR: 1.000e-04  Grad: 4.231e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [334/469][  2210]  Loss: 0.205 (0.103)  Acc: 95.7 (97.8)  LR: 1.000e-04  Grad: 6.882e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [344/469][  2220]  Loss: 0.0638 (0.103)  Acc: 98.0 (97.8)  LR: 1.000e-04  Grad: 1.038e+01  Time: 0.023,0.207 1234/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [354/469][  2230]  Loss: 0.0463 (0.102)  Acc: 99.6 (97.8)  LR: 1.000e-04  Grad: 2.266e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [364/469][  2240]  Loss: 0.0635 (0.101)  Acc: 98.4 (97.8)  LR: 1.000e-04  Grad: 2.442e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [374/469][  2250]  Loss: 0.0597 (0.101)  Acc: 98.8 (97.8)  LR: 1.000e-04  Grad: 5.219e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [384/469][  2260]  Loss: 0.0624 (0.101)  Acc: 98.4 (97.8)  LR: 1.000e-04  Grad: 1.945e+00  Time: 0.023,0.207 1236/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [394/469][  2270]  Loss: 0.0893 (0.100)  Acc: 98.4 (97.8)  LR: 1.000e-04  Grad: 8.286e+00  Time: 0.023,0.207 1236/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [404/469][  2280]  Loss: 0.117 (0.100)  Acc: 97.7 (97.8)  LR: 1.000e-04  Grad: 7.296e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [414/469][  2290]  Loss: 0.0353 (0.0990)  Acc: 99.6 (97.9)  LR: 1.000e-04  Grad: 1.966e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [424/469][  2300]  Loss: 0.121 (0.0986)  Acc: 96.5 (97.9)  LR: 1.000e-04  Grad: 4.011e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [434/469][  2310]  Loss: 0.0822 (0.0982)  Acc: 98.0 (97.9)  LR: 1.000e-04  Grad: 3.610e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [444/469][  2320]  Loss: 0.0317 (0.0979)  Acc: 99.6 (97.9)  LR: 1.000e-04  Grad: 2.840e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [454/469][  2330]  Loss: 0.0534 (0.0978)  Acc: 98.8 (97.9)  LR: 1.000e-04  Grad: 2.596e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [464/469][  2340]  Loss: 0.106 (0.0973)  Acc: 98.4 (97.9)  LR: 1.000e-04  Grad: 4.593e+00  Time: 0.023,0.207 1239/s  Mem: 11.57,13.07 GB\n",
      "Train:   4 [468/469][  2344]  Loss: 0.0892 (0.0974)  Acc: 98.4 (97.9)  LR: 1.000e-04  Grad: 1.908e+01  Time: 0.023,0.207 1239/s  Mem: 11.57,13.07 GB\n",
      "Val:   4 [  0/20]  Loss: 6.70 (6.70)  Acc: 3.12 (3.12)  Time: 1.032,1.102 232/s  Mem: 3.53,13.17 GB\n",
      "Val:   4 [ 10/20]  Loss: 6.71 (6.62)  Acc: 2.73 (3.20)  Time: 0.158,0.227 1125/s  Mem: 5.39,13.22 GB\n",
      "Val:   4 [ 19/20]  Loss: 6.84 (6.59)  Acc: 2.94 (3.36)  Time: 0.121,0.189 1351/s  Mem: 5.39,13.22 GB\n",
      "Starting epoch 5\n",
      "Train:   5 [  5/469][  2350]  Loss: 0.121 (0.116)  Acc: 98.0 (97.8)  LR: 1.000e-04  Grad: 4.720e+00  Time: 0.188,0.372 688/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 15/469][  2360]  Loss: 0.0572 (0.0909)  Acc: 99.2 (98.1)  LR: 1.000e-04  Grad: 4.609e+00  Time: 0.084,0.267 957/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 25/469][  2370]  Loss: 0.109 (0.0886)  Acc: 97.7 (98.2)  LR: 1.000e-04  Grad: 9.440e+00  Time: 0.059,0.243 1053/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 35/469][  2380]  Loss: 0.0419 (0.0869)  Acc: 99.2 (98.1)  LR: 1.000e-04  Grad: 2.084e+00  Time: 0.048,0.232 1102/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 45/469][  2390]  Loss: 0.0381 (0.0816)  Acc: 99.2 (98.2)  LR: 1.000e-04  Grad: 2.278e+00  Time: 0.042,0.226 1132/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 55/469][  2400]  Loss: 0.0973 (0.0785)  Acc: 97.7 (98.3)  LR: 1.000e-04  Grad: 4.881e+00  Time: 0.038,0.222 1152/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 65/469][  2410]  Loss: 0.0937 (0.0796)  Acc: 98.0 (98.3)  LR: 1.000e-04  Grad: 8.034e+00  Time: 0.036,0.220 1166/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 75/469][  2420]  Loss: 0.0922 (0.0823)  Acc: 97.7 (98.2)  LR: 1.000e-04  Grad: 5.110e+00  Time: 0.034,0.218 1175/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 85/469][  2430]  Loss: 0.0915 (0.0843)  Acc: 98.0 (98.2)  LR: 1.000e-04  Grad: 4.117e+00  Time: 0.032,0.216 1183/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [ 95/469][  2440]  Loss: 0.0718 (0.0840)  Acc: 99.2 (98.2)  LR: 1.000e-04  Grad: 1.428e+00  Time: 0.031,0.215 1190/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [105/469][  2450]  Loss: 0.0817 (0.0826)  Acc: 97.3 (98.2)  LR: 1.000e-04  Grad: 6.483e+00  Time: 0.030,0.214 1195/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [115/469][  2460]  Loss: 0.0368 (0.0825)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 2.827e+00  Time: 0.029,0.213 1199/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [125/469][  2470]  Loss: 0.129 (0.0820)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 1.261e+01  Time: 0.029,0.213 1203/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [135/469][  2480]  Loss: 0.0877 (0.0825)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 3.879e+00  Time: 0.028,0.212 1207/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [145/469][  2490]  Loss: 0.0904 (0.0828)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 3.089e+00  Time: 0.028,0.212 1210/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [155/469][  2500]  Loss: 0.0538 (0.0818)  Acc: 99.2 (98.3)  LR: 1.000e-04  Grad: 2.149e+00  Time: 0.027,0.211 1212/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [165/469][  2510]  Loss: 0.0709 (0.0806)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 5.642e+00  Time: 0.027,0.211 1215/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [175/469][  2520]  Loss: 0.122 (0.0813)  Acc: 97.7 (98.3)  LR: 1.000e-04  Grad: 2.404e+00  Time: 0.027,0.211 1216/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [185/469][  2530]  Loss: 0.0413 (0.0820)  Acc: 99.2 (98.3)  LR: 1.000e-04  Grad: 2.375e+00  Time: 0.026,0.210 1218/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [195/469][  2540]  Loss: 0.0391 (0.0817)  Acc: 99.2 (98.3)  LR: 1.000e-04  Grad: 2.130e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [205/469][  2550]  Loss: 0.0280 (0.0804)  Acc: 99.6 (98.3)  LR: 1.000e-04  Grad: 3.689e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [215/469][  2560]  Loss: 0.0883 (0.0807)  Acc: 96.9 (98.3)  LR: 1.000e-04  Grad: 3.418e+00  Time: 0.026,0.210 1221/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [225/469][  2570]  Loss: 0.0717 (0.0791)  Acc: 98.8 (98.4)  LR: 1.000e-04  Grad: 2.376e+00  Time: 0.026,0.210 1222/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [235/469][  2580]  Loss: 0.0445 (0.0783)  Acc: 99.2 (98.4)  LR: 1.000e-04  Grad: 1.867e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [245/469][  2590]  Loss: 0.112 (0.0789)  Acc: 98.4 (98.4)  LR: 1.000e-04  Grad: 5.099e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [255/469][  2600]  Loss: 0.112 (0.0789)  Acc: 98.8 (98.4)  LR: 1.000e-04  Grad: 4.277e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [265/469][  2610]  Loss: 0.107 (0.0791)  Acc: 97.7 (98.4)  LR: 1.000e-04  Grad: 2.803e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [275/469][  2620]  Loss: 0.114 (0.0793)  Acc: 97.3 (98.3)  LR: 1.000e-04  Grad: 2.997e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [285/469][  2630]  Loss: 0.0579 (0.0798)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 1.988e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [295/469][  2640]  Loss: 0.0398 (0.0799)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 2.318e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [305/469][  2650]  Loss: 0.0850 (0.0794)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 4.390e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [315/469][  2660]  Loss: 0.0686 (0.0797)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 2.938e+00  Time: 0.025,0.209 1228/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [325/469][  2670]  Loss: 0.126 (0.0797)  Acc: 97.3 (98.3)  LR: 1.000e-04  Grad: 3.299e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [335/469][  2680]  Loss: 0.104 (0.0802)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 2.852e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [345/469][  2690]  Loss: 0.0969 (0.0804)  Acc: 98.0 (98.3)  LR: 1.000e-04  Grad: 5.102e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [355/469][  2700]  Loss: 0.0296 (0.0797)  Acc: 99.6 (98.3)  LR: 1.000e-04  Grad: 4.093e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [365/469][  2710]  Loss: 0.0304 (0.0792)  Acc: 99.6 (98.3)  LR: 1.000e-04  Grad: 1.151e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [375/469][  2720]  Loss: 0.0361 (0.0792)  Acc: 99.2 (98.3)  LR: 1.000e-04  Grad: 1.543e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [385/469][  2730]  Loss: 0.0567 (0.0790)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 4.315e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [395/469][  2740]  Loss: 0.0441 (0.0789)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 2.581e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [405/469][  2750]  Loss: 0.0606 (0.0790)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 2.571e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [415/469][  2760]  Loss: 0.0495 (0.0792)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 6.865e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [425/469][  2770]  Loss: 0.159 (0.0792)  Acc: 97.3 (98.3)  LR: 1.000e-04  Grad: 4.591e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [435/469][  2780]  Loss: 0.0569 (0.0792)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 2.667e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [445/469][  2790]  Loss: 0.0275 (0.0789)  Acc: 99.2 (98.3)  LR: 1.000e-04  Grad: 2.626e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [455/469][  2800]  Loss: 0.119 (0.0793)  Acc: 96.9 (98.3)  LR: 1.000e-04  Grad: 3.826e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [465/469][  2810]  Loss: 0.0573 (0.0788)  Acc: 98.8 (98.3)  LR: 1.000e-04  Grad: 3.834e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.37 GB\n",
      "Train:   5 [468/469][  2813]  Loss: 0.191 (0.0790)  Acc: 96.4 (98.3)  LR: 1.000e-04  Grad: 6.918e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.37 GB\n",
      "Val:   5 [  0/20]  Loss: 6.52 (6.52)  Acc: 5.47 (5.47)  Time: 0.933,1.003 255/s  Mem: 3.53,13.47 GB\n",
      "Val:   5 [ 10/20]  Loss: 6.97 (6.75)  Acc: 3.52 (3.52)  Time: 0.149,0.218 1175/s  Mem: 5.39,13.52 GB\n",
      "Val:   5 [ 19/20]  Loss: 6.46 (6.74)  Acc: 3.68 (3.68)  Time: 0.115,0.184 1392/s  Mem: 5.39,13.52 GB\n",
      "Starting epoch 6\n",
      "Train:   6 [  6/469][  2820]  Loss: 0.0691 (0.0756)  Acc: 98.4 (98.3)  LR: 1.000e-04  Grad: 1.696e+01  Time: 0.159,0.343 747/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 16/469][  2830]  Loss: 0.0782 (0.0753)  Acc: 98.0 (98.3)  LR: 1.000e-04  Grad: 5.799e+00  Time: 0.078,0.262 977/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 26/469][  2840]  Loss: 0.0547 (0.0700)  Acc: 98.8 (98.5)  LR: 1.000e-04  Grad: 4.750e+00  Time: 0.057,0.241 1062/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 36/469][  2850]  Loss: 0.0488 (0.0714)  Acc: 98.4 (98.5)  LR: 1.000e-04  Grad: 1.692e+00  Time: 0.048,0.231 1106/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 46/469][  2860]  Loss: 0.0727 (0.0705)  Acc: 98.0 (98.5)  LR: 1.000e-04  Grad: 7.362e+00  Time: 0.042,0.226 1133/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 56/469][  2870]  Loss: 0.121 (0.0767)  Acc: 97.7 (98.4)  LR: 1.000e-04  Grad: 3.547e+00  Time: 0.038,0.222 1152/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 66/469][  2880]  Loss: 0.0579 (0.0751)  Acc: 98.0 (98.4)  LR: 1.000e-04  Grad: 2.509e+00  Time: 0.036,0.220 1165/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 76/469][  2890]  Loss: 0.134 (0.0758)  Acc: 97.3 (98.4)  LR: 1.000e-04  Grad: 4.911e+00  Time: 0.034,0.218 1175/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 86/469][  2900]  Loss: 0.0211 (0.0741)  Acc: 99.6 (98.4)  LR: 1.000e-04  Grad: 8.538e-01  Time: 0.032,0.216 1183/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [ 96/469][  2910]  Loss: 0.0229 (0.0707)  Acc: 99.6 (98.5)  LR: 1.000e-04  Grad: 1.448e+00  Time: 0.031,0.215 1189/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [106/469][  2920]  Loss: 0.0682 (0.0718)  Acc: 98.4 (98.5)  LR: 1.000e-04  Grad: 3.171e+00  Time: 0.030,0.214 1194/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [116/469][  2930]  Loss: 0.151 (0.0723)  Acc: 96.5 (98.5)  LR: 1.000e-04  Grad: 4.828e+00  Time: 0.030,0.214 1199/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [126/469][  2940]  Loss: 0.125 (0.0725)  Acc: 97.7 (98.4)  LR: 1.000e-04  Grad: 3.397e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [136/469][  2950]  Loss: 0.0568 (0.0718)  Acc: 98.4 (98.5)  LR: 1.000e-04  Grad: 9.247e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [146/469][  2960]  Loss: 0.148 (0.0727)  Acc: 97.3 (98.4)  LR: 1.000e-04  Grad: 7.472e+00  Time: 0.028,0.212 1208/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [156/469][  2970]  Loss: 0.0599 (0.0732)  Acc: 98.8 (98.4)  LR: 1.000e-04  Grad: 1.855e+00  Time: 0.028,0.211 1210/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [166/469][  2980]  Loss: 0.0823 (0.0740)  Acc: 98.8 (98.4)  LR: 1.000e-04  Grad: 2.586e+00  Time: 0.027,0.211 1213/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [176/469][  2990]  Loss: 0.0795 (0.0734)  Acc: 98.8 (98.4)  LR: 1.000e-04  Grad: 2.203e+00  Time: 0.027,0.211 1214/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [186/469][  3000]  Loss: 0.0483 (0.0737)  Acc: 99.2 (98.4)  LR: 1.000e-04  Grad: 5.609e+00  Time: 0.027,0.211 1216/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [196/469][  3010]  Loss: 0.0529 (0.0735)  Acc: 98.8 (98.4)  LR: 1.000e-04  Grad: 3.586e+00  Time: 0.026,0.210 1218/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [206/469][  3020]  Loss: 0.0805 (0.0731)  Acc: 98.0 (98.4)  LR: 1.000e-04  Grad: 2.994e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [216/469][  3030]  Loss: 0.0786 (0.0730)  Acc: 98.4 (98.5)  LR: 1.000e-04  Grad: 3.589e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [226/469][  3040]  Loss: 0.0439 (0.0719)  Acc: 99.2 (98.5)  LR: 1.000e-04  Grad: 3.504e+00  Time: 0.026,0.210 1222/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [236/469][  3050]  Loss: 0.0414 (0.0709)  Acc: 99.2 (98.5)  LR: 1.000e-04  Grad: 2.587e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [246/469][  3060]  Loss: 0.0434 (0.0705)  Acc: 98.8 (98.5)  LR: 1.000e-04  Grad: 3.990e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [256/469][  3070]  Loss: 0.0544 (0.0697)  Acc: 98.0 (98.5)  LR: 1.000e-04  Grad: 2.486e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [266/469][  3080]  Loss: 0.0359 (0.0690)  Acc: 99.6 (98.5)  LR: 1.000e-04  Grad: 2.685e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [276/469][  3090]  Loss: 0.0396 (0.0689)  Acc: 99.2 (98.5)  LR: 1.000e-04  Grad: 1.393e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [286/469][  3100]  Loss: 0.0202 (0.0687)  Acc: 99.6 (98.6)  LR: 1.000e-04  Grad: 8.423e-01  Time: 0.025,0.209 1227/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [296/469][  3110]  Loss: 0.0610 (0.0684)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 3.753e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [306/469][  3120]  Loss: 0.0291 (0.0680)  Acc: 99.6 (98.6)  LR: 1.000e-04  Grad: 1.374e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [316/469][  3130]  Loss: 0.0391 (0.0684)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 3.035e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [326/469][  3140]  Loss: 0.0359 (0.0678)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 2.617e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [336/469][  3150]  Loss: 0.0244 (0.0675)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 2.091e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [346/469][  3160]  Loss: 0.0344 (0.0675)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 8.303e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [356/469][  3170]  Loss: 0.0644 (0.0673)  Acc: 98.0 (98.6)  LR: 1.000e-04  Grad: 5.617e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [366/469][  3180]  Loss: 0.0521 (0.0672)  Acc: 98.0 (98.6)  LR: 1.000e-04  Grad: 3.562e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [376/469][  3190]  Loss: 0.0521 (0.0672)  Acc: 98.8 (98.6)  LR: 1.000e-04  Grad: 3.485e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [386/469][  3200]  Loss: 0.0447 (0.0667)  Acc: 98.8 (98.6)  LR: 1.000e-04  Grad: 3.642e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [396/469][  3210]  Loss: 0.0521 (0.0662)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 2.373e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [406/469][  3220]  Loss: 0.108 (0.0667)  Acc: 98.0 (98.6)  LR: 1.000e-04  Grad: 3.572e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [416/469][  3230]  Loss: 0.0790 (0.0667)  Acc: 98.8 (98.6)  LR: 1.000e-04  Grad: 3.891e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [426/469][  3240]  Loss: 0.0546 (0.0663)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 4.266e+00  Time: 0.024,0.208 1234/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [436/469][  3250]  Loss: 0.122 (0.0665)  Acc: 98.0 (98.6)  LR: 1.000e-04  Grad: 2.531e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [446/469][  3260]  Loss: 0.0690 (0.0666)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 2.361e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [456/469][  3270]  Loss: 0.0653 (0.0666)  Acc: 98.0 (98.6)  LR: 1.000e-04  Grad: 8.829e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [466/469][  3280]  Loss: 0.0736 (0.0667)  Acc: 97.3 (98.6)  LR: 1.000e-04  Grad: 6.566e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.68 GB\n",
      "Train:   6 [468/469][  3282]  Loss: 0.0618 (0.0668)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 3.623e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.68 GB\n",
      "Val:   6 [  0/20]  Loss: 6.84 (6.84)  Acc: 3.12 (3.12)  Time: 1.056,1.126 227/s  Mem: 3.53,13.78 GB\n",
      "Val:   6 [ 10/20]  Loss: 7.15 (6.81)  Acc: 3.12 (3.76)  Time: 0.166,0.235 1089/s  Mem: 5.39,13.83 GB\n",
      "Val:   6 [ 19/20]  Loss: 7.03 (6.82)  Acc: 2.94 (3.66)  Time: 0.126,0.194 1319/s  Mem: 5.39,13.83 GB\n",
      "Starting epoch 7\n",
      "Train:   7 [  7/469][  3290]  Loss: 0.0388 (0.0634)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 3.540e+00  Time: 0.148,0.332 771/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 17/469][  3300]  Loss: 0.0488 (0.0665)  Acc: 98.0 (98.4)  LR: 1.000e-04  Grad: 6.422e+00  Time: 0.078,0.262 976/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 27/469][  3310]  Loss: 0.0901 (0.0621)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 3.517e+00  Time: 0.058,0.242 1059/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 37/469][  3320]  Loss: 0.0931 (0.0645)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 1.969e+00  Time: 0.048,0.232 1103/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 47/469][  3330]  Loss: 0.0527 (0.0685)  Acc: 98.8 (98.5)  LR: 1.000e-04  Grad: 2.594e+00  Time: 0.042,0.226 1131/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 57/469][  3340]  Loss: 0.0390 (0.0676)  Acc: 99.6 (98.6)  LR: 1.000e-04  Grad: 1.938e+00  Time: 0.039,0.223 1150/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 67/469][  3350]  Loss: 0.0710 (0.0672)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 3.389e+00  Time: 0.036,0.220 1163/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 77/469][  3360]  Loss: 0.112 (0.0702)  Acc: 97.7 (98.5)  LR: 1.000e-04  Grad: 2.433e+00  Time: 0.034,0.218 1174/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 87/469][  3370]  Loss: 0.0242 (0.0687)  Acc: 99.6 (98.5)  LR: 1.000e-04  Grad: 9.659e-01  Time: 0.033,0.217 1182/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [ 97/469][  3380]  Loss: 0.0355 (0.0677)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 2.399e+00  Time: 0.031,0.215 1189/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [107/469][  3390]  Loss: 0.111 (0.0678)  Acc: 98.0 (98.6)  LR: 1.000e-04  Grad: 4.270e+00  Time: 0.030,0.214 1194/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [117/469][  3400]  Loss: 0.0682 (0.0668)  Acc: 98.4 (98.6)  LR: 1.000e-04  Grad: 4.409e+00  Time: 0.030,0.214 1199/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [127/469][  3410]  Loss: 0.0231 (0.0658)  Acc: 99.2 (98.6)  LR: 1.000e-04  Grad: 2.317e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [137/469][  3420]  Loss: 0.0266 (0.0649)  Acc: 99.6 (98.6)  LR: 1.000e-04  Grad: 1.929e+00  Time: 0.028,0.212 1206/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [147/469][  3430]  Loss: 0.0682 (0.0634)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 2.578e+00  Time: 0.028,0.212 1209/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [157/469][  3440]  Loss: 0.0607 (0.0623)  Acc: 98.8 (98.7)  LR: 1.000e-04  Grad: 2.625e+00  Time: 0.027,0.211 1211/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [167/469][  3450]  Loss: 0.0225 (0.0617)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 1.750e+00  Time: 0.027,0.211 1213/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [177/469][  3460]  Loss: 0.0602 (0.0622)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 3.786e+00  Time: 0.027,0.211 1215/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [187/469][  3470]  Loss: 0.0232 (0.0621)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 3.328e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [197/469][  3480]  Loss: 0.113 (0.0633)  Acc: 98.0 (98.7)  LR: 1.000e-04  Grad: 2.765e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [207/469][  3490]  Loss: 0.0219 (0.0627)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 6.560e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [217/469][  3500]  Loss: 0.0891 (0.0628)  Acc: 98.8 (98.7)  LR: 1.000e-04  Grad: 5.393e+00  Time: 0.026,0.210 1222/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [227/469][  3510]  Loss: 0.0657 (0.0626)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 3.208e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [237/469][  3520]  Loss: 0.0220 (0.0625)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 1.673e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [247/469][  3530]  Loss: 0.0768 (0.0624)  Acc: 98.8 (98.7)  LR: 1.000e-04  Grad: 7.857e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [257/469][  3540]  Loss: 0.104 (0.0622)  Acc: 98.0 (98.7)  LR: 1.000e-04  Grad: 2.709e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [267/469][  3550]  Loss: 0.0540 (0.0623)  Acc: 99.2 (98.7)  LR: 1.000e-04  Grad: 2.349e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [277/469][  3560]  Loss: 0.0387 (0.0624)  Acc: 99.2 (98.7)  LR: 1.000e-04  Grad: 2.691e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [287/469][  3570]  Loss: 0.0220 (0.0617)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 1.663e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [297/469][  3580]  Loss: 0.0609 (0.0613)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 4.427e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [307/469][  3590]  Loss: 0.0274 (0.0610)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 1.985e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [317/469][  3600]  Loss: 0.0913 (0.0605)  Acc: 97.7 (98.7)  LR: 1.000e-04  Grad: 3.785e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [327/469][  3610]  Loss: 0.0402 (0.0600)  Acc: 99.2 (98.7)  LR: 1.000e-04  Grad: 2.730e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [337/469][  3620]  Loss: 0.0654 (0.0602)  Acc: 97.7 (98.7)  LR: 1.000e-04  Grad: 1.058e+01  Time: 0.024,0.208 1232/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [347/469][  3630]  Loss: 0.111 (0.0602)  Acc: 97.3 (98.7)  LR: 1.000e-04  Grad: 5.419e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [357/469][  3640]  Loss: 0.0695 (0.0599)  Acc: 98.0 (98.7)  LR: 1.000e-04  Grad: 4.905e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [367/469][  3650]  Loss: 0.0793 (0.0597)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 3.958e+00  Time: 0.023,0.208 1234/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [377/469][  3660]  Loss: 0.0629 (0.0594)  Acc: 99.2 (98.7)  LR: 1.000e-04  Grad: 3.059e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [387/469][  3670]  Loss: 0.0251 (0.0596)  Acc: 99.6 (98.7)  LR: 1.000e-04  Grad: 1.414e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [397/469][  3680]  Loss: 0.0856 (0.0594)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 2.128e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [407/469][  3690]  Loss: 0.0883 (0.0597)  Acc: 98.0 (98.7)  LR: 1.000e-04  Grad: 2.363e+00  Time: 0.023,0.207 1236/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [417/469][  3700]  Loss: 0.0683 (0.0600)  Acc: 98.8 (98.7)  LR: 1.000e-04  Grad: 1.441e+01  Time: 0.023,0.207 1236/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [427/469][  3710]  Loss: 0.0456 (0.0597)  Acc: 98.4 (98.7)  LR: 1.000e-04  Grad: 3.366e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [437/469][  3720]  Loss: 0.0489 (0.0594)  Acc: 98.8 (98.7)  LR: 1.000e-04  Grad: 9.368e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [447/469][  3730]  Loss: 0.160 (0.0594)  Acc: 96.5 (98.7)  LR: 1.000e-04  Grad: 7.543e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [457/469][  3740]  Loss: 0.0873 (0.0593)  Acc: 98.0 (98.7)  LR: 1.000e-04  Grad: 1.398e+01  Time: 0.023,0.207 1238/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [467/469][  3750]  Loss: 0.115 (0.0594)  Acc: 97.7 (98.7)  LR: 1.000e-04  Grad: 4.928e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,13.98 GB\n",
      "Train:   7 [468/469][  3751]  Loss: 0.0247 (0.0594)  Acc: 99.5 (98.7)  LR: 1.000e-04  Grad: 4.055e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,13.98 GB\n",
      "Val:   7 [  0/20]  Loss: 6.77 (6.77)  Acc: 3.52 (3.52)  Time: 1.031,1.101 233/s  Mem: 3.53,14.09 GB\n",
      "Val:   7 [ 10/20]  Loss: 6.86 (6.87)  Acc: 4.30 (2.98)  Time: 0.161,0.231 1110/s  Mem: 5.39,14.14 GB\n",
      "Val:   7 [ 19/20]  Loss: 6.86 (6.89)  Acc: 2.94 (3.34)  Time: 0.124,0.192 1331/s  Mem: 5.39,14.14 GB\n",
      "Starting epoch 8\n",
      "Train:   8 [  8/469][  3760]  Loss: 0.0193 (0.0587)  Acc: 99.2 (98.7)  LR: 1.000e-04  Grad: 3.975e+00  Time: 0.129,0.313 819/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 18/469][  3770]  Loss: 0.0195 (0.0522)  Acc: 99.6 (98.8)  LR: 1.000e-04  Grad: 1.898e+00  Time: 0.072,0.256 1001/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 28/469][  3780]  Loss: 0.0855 (0.0544)  Acc: 98.0 (98.8)  LR: 1.000e-04  Grad: 3.254e+00  Time: 0.054,0.238 1075/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 38/469][  3790]  Loss: 0.0534 (0.0574)  Acc: 99.2 (98.7)  LR: 1.000e-04  Grad: 1.422e+00  Time: 0.046,0.229 1116/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 48/469][  3800]  Loss: 0.0259 (0.0558)  Acc: 99.6 (98.8)  LR: 1.000e-04  Grad: 3.224e+00  Time: 0.040,0.224 1141/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 58/469][  3810]  Loss: 0.0430 (0.0526)  Acc: 98.8 (98.8)  LR: 1.000e-04  Grad: 2.834e+00  Time: 0.037,0.221 1159/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 68/469][  3820]  Loss: 0.0466 (0.0518)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 5.359e+00  Time: 0.035,0.219 1172/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 78/469][  3830]  Loss: 0.112 (0.0531)  Acc: 97.7 (98.8)  LR: 1.000e-04  Grad: 1.479e+01  Time: 0.033,0.217 1182/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 88/469][  3840]  Loss: 0.0512 (0.0540)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 1.513e+00  Time: 0.031,0.215 1189/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [ 98/469][  3850]  Loss: 0.0299 (0.0546)  Acc: 98.8 (98.8)  LR: 1.000e-04  Grad: 2.817e+00  Time: 0.030,0.214 1196/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [108/469][  3860]  Loss: 0.148 (0.0571)  Acc: 97.3 (98.8)  LR: 1.000e-04  Grad: 4.854e+00  Time: 0.029,0.213 1201/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [118/469][  3870]  Loss: 0.0160 (0.0564)  Acc: 99.6 (98.8)  LR: 1.000e-04  Grad: 4.890e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [128/469][  3880]  Loss: 0.0174 (0.0558)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 1.841e+00  Time: 0.028,0.212 1209/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [138/469][  3890]  Loss: 0.0545 (0.0554)  Acc: 98.4 (98.8)  LR: 1.000e-04  Grad: 3.034e+00  Time: 0.027,0.211 1212/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [148/469][  3900]  Loss: 0.0603 (0.0552)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 2.781e+00  Time: 0.027,0.211 1215/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [158/469][  3910]  Loss: 0.0548 (0.0557)  Acc: 98.8 (98.8)  LR: 1.000e-04  Grad: 4.392e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [168/469][  3920]  Loss: 0.0519 (0.0561)  Acc: 98.8 (98.8)  LR: 1.000e-04  Grad: 1.801e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [178/469][  3930]  Loss: 0.0777 (0.0564)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 2.456e+00  Time: 0.026,0.210 1221/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [188/469][  3940]  Loss: 0.0462 (0.0560)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 3.747e+00  Time: 0.025,0.209 1222/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [198/469][  3950]  Loss: 0.0275 (0.0555)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 2.165e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [208/469][  3960]  Loss: 0.0142 (0.0548)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 1.712e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [218/469][  3970]  Loss: 0.0590 (0.0545)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 1.603e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [228/469][  3980]  Loss: 0.0627 (0.0541)  Acc: 98.0 (98.9)  LR: 1.000e-04  Grad: 4.430e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [238/469][  3990]  Loss: 0.0742 (0.0549)  Acc: 98.8 (98.8)  LR: 1.000e-04  Grad: 1.804e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [248/469][  4000]  Loss: 0.0321 (0.0547)  Acc: 98.8 (98.8)  LR: 1.000e-04  Grad: 3.448e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [258/469][  4010]  Loss: 0.0516 (0.0543)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 3.395e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [268/469][  4020]  Loss: 0.102 (0.0545)  Acc: 97.7 (98.8)  LR: 1.000e-04  Grad: 5.319e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [278/469][  4030]  Loss: 0.0381 (0.0549)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 4.358e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [288/469][  4040]  Loss: 0.0460 (0.0547)  Acc: 99.2 (98.8)  LR: 1.000e-04  Grad: 2.893e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [298/469][  4050]  Loss: 0.00654 (0.0547)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 1.016e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [308/469][  4060]  Loss: 0.0866 (0.0547)  Acc: 98.0 (98.9)  LR: 1.000e-04  Grad: 4.550e+00  Time: 0.023,0.207 1234/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [318/469][  4070]  Loss: 0.136 (0.0547)  Acc: 97.3 (98.8)  LR: 1.000e-04  Grad: 3.044e+00  Time: 0.023,0.207 1235/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [328/469][  4080]  Loss: 0.0819 (0.0540)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 2.077e+00  Time: 0.023,0.207 1236/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [338/469][  4090]  Loss: 0.0177 (0.0542)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 2.169e+00  Time: 0.023,0.207 1236/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [348/469][  4100]  Loss: 0.0525 (0.0544)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 2.717e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [358/469][  4110]  Loss: 0.0298 (0.0543)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.357e+00  Time: 0.023,0.207 1237/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [368/469][  4120]  Loss: 0.0635 (0.0538)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 3.232e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [378/469][  4130]  Loss: 0.00673 (0.0533)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 7.247e-01  Time: 0.023,0.207 1238/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [388/469][  4140]  Loss: 0.0323 (0.0530)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 2.166e+00  Time: 0.023,0.207 1238/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [398/469][  4150]  Loss: 0.0374 (0.0529)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 2.597e+00  Time: 0.023,0.207 1239/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [408/469][  4160]  Loss: 0.0650 (0.0526)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 4.980e+00  Time: 0.023,0.207 1239/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [418/469][  4170]  Loss: 0.0233 (0.0522)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.039e+01  Time: 0.023,0.207 1239/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [428/469][  4180]  Loss: 0.0420 (0.0522)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 5.174e+00  Time: 0.023,0.207 1240/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [438/469][  4190]  Loss: 0.0499 (0.0522)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 2.331e+00  Time: 0.022,0.206 1240/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [448/469][  4200]  Loss: 0.0859 (0.0520)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 3.536e+00  Time: 0.022,0.206 1240/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [458/469][  4210]  Loss: 0.0109 (0.0516)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.674e+00  Time: 0.022,0.206 1240/s  Mem: 11.57,14.29 GB\n",
      "Train:   8 [468/469][  4220]  Loss: 0.0203 (0.0515)  Acc: 99.5 (98.9)  LR: 1.000e-04  Grad: 2.409e+00  Time: 0.022,0.206 1241/s  Mem: 11.57,14.29 GB\n",
      "Val:   8 [  0/20]  Loss: 6.94 (6.94)  Acc: 4.30 (4.30)  Time: 0.927,0.997 257/s  Mem: 3.53,14.39 GB\n",
      "Val:   8 [ 10/20]  Loss: 7.15 (7.05)  Acc: 1.56 (3.52)  Time: 0.150,0.219 1170/s  Mem: 5.39,14.44 GB\n",
      "Val:   8 [ 19/20]  Loss: 7.33 (7.12)  Acc: 3.68 (3.46)  Time: 0.116,0.185 1386/s  Mem: 5.39,14.44 GB\n",
      "Starting epoch 9\n",
      "Train:   9 [  9/469][  4230]  Loss: 0.0552 (0.0491)  Acc: 99.2 (99.0)  LR: 1.000e-04  Grad: 1.288e+00  Time: 0.119,0.303 845/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 19/469][  4240]  Loss: 0.0164 (0.0541)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 2.008e+00  Time: 0.070,0.254 1008/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 29/469][  4250]  Loss: 0.0238 (0.0545)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 1.885e+00  Time: 0.054,0.238 1078/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 39/469][  4260]  Loss: 0.0714 (0.0533)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 5.452e+00  Time: 0.045,0.229 1116/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 49/469][  4270]  Loss: 0.0664 (0.0513)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 8.019e+00  Time: 0.041,0.225 1140/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 59/469][  4280]  Loss: 0.0694 (0.0516)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 3.482e+00  Time: 0.037,0.221 1157/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 69/469][  4290]  Loss: 0.00824 (0.0494)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 6.336e-01  Time: 0.035,0.219 1169/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 79/469][  4300]  Loss: 0.0786 (0.0508)  Acc: 97.7 (98.9)  LR: 1.000e-04  Grad: 3.374e+00  Time: 0.033,0.217 1179/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 89/469][  4310]  Loss: 0.0510 (0.0508)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 2.342e+00  Time: 0.032,0.216 1186/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [ 99/469][  4320]  Loss: 0.0712 (0.0519)  Acc: 98.0 (98.9)  LR: 1.000e-04  Grad: 4.545e+00  Time: 0.031,0.215 1192/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [109/469][  4330]  Loss: 0.0446 (0.0521)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 4.131e+00  Time: 0.030,0.214 1197/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [119/469][  4340]  Loss: 0.0423 (0.0509)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 2.236e+00  Time: 0.029,0.213 1202/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [129/469][  4350]  Loss: 0.0721 (0.0508)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 1.409e+00  Time: 0.028,0.212 1205/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [139/469][  4360]  Loss: 0.0462 (0.0500)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 2.194e+00  Time: 0.028,0.212 1208/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [149/469][  4370]  Loss: 0.0166 (0.0494)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.823e+00  Time: 0.027,0.211 1211/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [159/469][  4380]  Loss: 0.0401 (0.0499)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 2.714e+00  Time: 0.027,0.211 1213/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [169/469][  4390]  Loss: 0.0346 (0.0490)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 3.159e+00  Time: 0.027,0.211 1215/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [179/469][  4400]  Loss: 0.0183 (0.0490)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.440e+00  Time: 0.026,0.210 1217/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [189/469][  4410]  Loss: 0.103 (0.0498)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 8.966e+00  Time: 0.026,0.210 1219/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [199/469][  4420]  Loss: 0.0457 (0.0510)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 3.352e+00  Time: 0.026,0.210 1220/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [209/469][  4430]  Loss: 0.0299 (0.0506)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 1.104e+00  Time: 0.026,0.210 1222/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [219/469][  4440]  Loss: 0.0726 (0.0511)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 3.348e+00  Time: 0.025,0.209 1223/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [229/469][  4450]  Loss: 0.0181 (0.0511)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.671e+00  Time: 0.025,0.209 1224/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [239/469][  4460]  Loss: 0.0157 (0.0513)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 1.618e+00  Time: 0.025,0.209 1225/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [249/469][  4470]  Loss: 0.0486 (0.0509)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 8.417e+00  Time: 0.025,0.209 1226/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [259/469][  4480]  Loss: 0.0911 (0.0509)  Acc: 98.0 (98.9)  LR: 1.000e-04  Grad: 2.632e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [269/469][  4490]  Loss: 0.0214 (0.0508)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 1.274e+00  Time: 0.025,0.209 1227/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [279/469][  4500]  Loss: 0.0111 (0.0503)  Acc: 99.6 (98.9)  LR: 1.000e-04  Grad: 1.998e+00  Time: 0.024,0.208 1228/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [289/469][  4510]  Loss: 0.0636 (0.0500)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 4.679e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [299/469][  4520]  Loss: 0.0304 (0.0499)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 1.927e+00  Time: 0.024,0.208 1229/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [309/469][  4530]  Loss: 0.112 (0.0498)  Acc: 97.7 (98.9)  LR: 1.000e-04  Grad: 5.886e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [319/469][  4540]  Loss: 0.0543 (0.0500)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 9.802e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [329/469][  4550]  Loss: 0.0413 (0.0504)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 4.169e+00  Time: 0.024,0.208 1230/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [339/469][  4560]  Loss: 0.0829 (0.0505)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 6.097e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [349/469][  4570]  Loss: 0.00716 (0.0505)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 1.283e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [359/469][  4580]  Loss: 0.0502 (0.0504)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 2.539e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [369/469][  4590]  Loss: 0.0668 (0.0511)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 8.252e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [379/469][  4600]  Loss: 0.0392 (0.0506)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 5.263e+00  Time: 0.024,0.208 1231/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [389/469][  4610]  Loss: 0.0681 (0.0507)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 5.061e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [399/469][  4620]  Loss: 0.100 (0.0503)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 4.140e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [409/469][  4630]  Loss: 0.0500 (0.0505)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 2.317e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [419/469][  4640]  Loss: 0.0411 (0.0504)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 5.195e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [429/469][  4650]  Loss: 0.114 (0.0505)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 3.404e+00  Time: 0.024,0.208 1232/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [439/469][  4660]  Loss: 0.0598 (0.0505)  Acc: 99.2 (98.9)  LR: 1.000e-04  Grad: 1.889e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [449/469][  4670]  Loss: 0.0619 (0.0505)  Acc: 98.4 (98.9)  LR: 1.000e-04  Grad: 3.464e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [459/469][  4680]  Loss: 0.0428 (0.0502)  Acc: 98.8 (98.9)  LR: 1.000e-04  Grad: 5.317e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,14.60 GB\n",
      "Train:   9 [468/469][  4689]  Loss: 0.0110 (0.0506)  Acc: 100. (98.9)  LR: 1.000e-04  Grad: 1.478e+00  Time: 0.024,0.208 1233/s  Mem: 11.57,14.60 GB\n",
      "Val:   9 [  0/20]  Loss: 7.16 (7.16)  Acc: 3.12 (3.12)  Time: 0.950,1.020 251/s  Mem: 3.53,14.70 GB\n",
      "Val:   9 [ 10/20]  Loss: 7.28 (7.12)  Acc: 3.52 (3.52)  Time: 0.150,0.219 1168/s  Mem: 5.39,14.75 GB\n",
      "Val:   9 [ 19/20]  Loss: 7.18 (7.11)  Acc: 4.41 (3.68)  Time: 0.116,0.185 1385/s  Mem: 5.39,14.75 GB\n",
      "Done! Run time: 1011s\n",
      "*** Final metric: 7.112\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(f\"Starting epoch {epoch:d}\")\n",
    "\n",
    "    train_one_epoch(\n",
    "        args=args,\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        task=task,\n",
    "        train_loader=loaders[\"train\"],\n",
    "        optimizer=optimizer,\n",
    "        lr_schedule=lr_schedule,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    metric = validate(\n",
    "        args=args,\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        task=task,\n",
    "        val_loader=loaders[\"validation\"],\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if args.debug:\n",
    "        break\n",
    "\n",
    "print(f\"Done! Run time: {time.monotonic() - start_time:.0f}s\")\n",
    "print(f\"*** Final metric: {metric:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01765d3ce26f41df83ee98fcbfead15b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04b26f4377954fca94efd1c1261f99d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06731d847b7e49289a35f074ea920a87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07336fc047f8452095b46069736deb86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c1b9ac3bf234d289284191f829f69b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32fdf84ecf53457eaaf317732f0738da",
       "IPY_MODEL_33be964ed6894b8b87c56e87930feb2d",
       "IPY_MODEL_866cd132fea7491eb848febe055cdab2"
      ],
      "layout": "IPY_MODEL_a92e1cf4a22c4b7e95a027bb86b75709"
     }
    },
    "0c402645285f4b269fadde9c779276cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de90fa4f9ba54b2c8d89f4c966897c37",
      "placeholder": "",
      "style": "IPY_MODEL_6cf04ec99af34c7fb68cb46dbfa326ad",
      "value": " 17/17 [00:00&lt;00:00, 596.98it/s]"
     }
    },
    "0ea0ff38154a45e4a5d453554c809df4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f119aa9ef39245e98b013c5cdd123a53",
      "placeholder": "",
      "style": "IPY_MODEL_bc399b203f1941a3873daca811f49f34",
      "value": "Resolving data files: 100%"
     }
    },
    "0fc60611aa364e72b7aa658b4dae3c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ea0ff38154a45e4a5d453554c809df4",
       "IPY_MODEL_1cdac0ae2755485abbac3ba0bb468a51",
       "IPY_MODEL_b5b07cac96994f0596867335ac5d6891"
      ],
      "layout": "IPY_MODEL_90c49878a5614f1e9216d883937d1aba"
     }
    },
    "1cdac0ae2755485abbac3ba0bb468a51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_830d9fbf96b44dfe860d0df6f4cbb326",
      "max": 17,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_504665b160c94e37bb2a3d9fa63f6b64",
      "value": 17
     }
    },
    "25efe34d268f4a7c9effa0964351a680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7186c6b7e060439c8ec623cd41e54f71",
      "max": 473219287,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_96137bad70224afbb39d22b75dd02a9e",
      "value": 473219287
     }
    },
    "2d6412040cee4509bdafaf3a9ce6e9f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab721dc5f40446c096a241a4c8b96a26",
      "max": 468367888,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba1f7331332040f0b3a094ca999d2933",
      "value": 222298112
     }
    },
    "32fdf84ecf53457eaaf317732f0738da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65f48f9661184f9a9857e8a6bc32a21b",
      "placeholder": "",
      "style": "IPY_MODEL_8997edcd43cf4864acc99bcd22b88a6a",
      "value": "Downloading data: 100%"
     }
    },
    "33be964ed6894b8b87c56e87930feb2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3323a1af573409798487e358ffbb007",
      "max": 451450200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e4a85e3d7284802a92c473485c307ef",
      "value": 451450200
     }
    },
    "33d5fabb269149f8894484bbc204bc06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d86ccec9bb2348859f061f086d066e26",
      "placeholder": "",
      "style": "IPY_MODEL_87e204547bf24e36b2e26cd9237c9e35",
      "value": "Downloading data: 100%"
     }
    },
    "480f0d498f474774a4f8d12e6add0322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48f253aaf3d049b69805fabb7890061a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a8ae1c437db41538c4452839d11034b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06731d847b7e49289a35f074ea920a87",
      "placeholder": "",
      "style": "IPY_MODEL_560c68a248754df4afcdda654472d93e",
      "value": " 508M/508M [00:43&lt;00:00, 13.9MB/s]"
     }
    },
    "504665b160c94e37bb2a3d9fa63f6b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "523b853154614b8a90e0ff7438ea2a49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "560c68a248754df4afcdda654472d93e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58a546cca9954ea1ac4aaac8fd228b0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9cb55392f0fd4b88a15a322c2dd40b0c",
       "IPY_MODEL_70241808d5914c8eb6022a80ccea0c5d",
       "IPY_MODEL_0c402645285f4b269fadde9c779276cd"
      ],
      "layout": "IPY_MODEL_5be1115682d1452e9c4e0f199a5e3634"
     }
    },
    "5a553ea40757446a9d068945c492bc34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5be1115682d1452e9c4e0f199a5e3634": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e4a85e3d7284802a92c473485c307ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "659d82d731d14e4499893e4506184200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a553ea40757446a9d068945c492bc34",
      "placeholder": "",
      "style": "IPY_MODEL_679e9fd07dcd49d4af0f4a7ecb00f9a0",
      "value": "Downloading data:  47%"
     }
    },
    "65f48f9661184f9a9857e8a6bc32a21b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "679e9fd07dcd49d4af0f4a7ecb00f9a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf04ec99af34c7fb68cb46dbfa326ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70241808d5914c8eb6022a80ccea0c5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea9e9908772441d89b3a59de94daf38b",
      "max": 17,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f779eb3b68c8471381e3ab8d1fa4b22b",
      "value": 17
     }
    },
    "7087efa6565846bbbc1bc32cad82ad81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7186c6b7e060439c8ec623cd41e54f71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7579f4c8b03a45498834acb1047f21c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "830d9fbf96b44dfe860d0df6f4cbb326": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "857b200869544cccb7b7b71abaaaf77d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "866cd132fea7491eb848febe055cdab2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48f253aaf3d049b69805fabb7890061a",
      "placeholder": "",
      "style": "IPY_MODEL_480f0d498f474774a4f8d12e6add0322",
      "value": " 451M/451M [00:43&lt;00:00, 9.16MB/s]"
     }
    },
    "86a27bb143f14fab9d26018b0900eb4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87e204547bf24e36b2e26cd9237c9e35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8997edcd43cf4864acc99bcd22b88a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90c49878a5614f1e9216d883937d1aba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96137bad70224afbb39d22b75dd02a9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9cb55392f0fd4b88a15a322c2dd40b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc7165a9d8ac456f9d93627d03bccb84",
      "placeholder": "",
      "style": "IPY_MODEL_86a27bb143f14fab9d26018b0900eb4b",
      "value": "Resolving data files: 100%"
     }
    },
    "a92e1cf4a22c4b7e95a027bb86b75709": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab721dc5f40446c096a241a4c8b96a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b05f23a34143457d82b70c8951225ee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b57ef3ddffed441bb8eca01f226b7c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5b07cac96994f0596867335ac5d6891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b26f4377954fca94efd1c1261f99d8",
      "placeholder": "",
      "style": "IPY_MODEL_f85183fb4b7d466495a7418e51d0cf3d",
      "value": " 17/17 [00:00&lt;00:00, 911.49it/s]"
     }
    },
    "b64054b68ba04de7a1558bea5516e872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc43cc63c67140e699206b14f8e0a062",
       "IPY_MODEL_25efe34d268f4a7c9effa0964351a680",
       "IPY_MODEL_d282699301ad46a89c380cf41ddd3f21"
      ],
      "layout": "IPY_MODEL_fe4ec3300c4f47828618edb5320f3d54"
     }
    },
    "ba1f7331332040f0b3a094ca999d2933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc399b203f1941a3873daca811f49f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c35cc17d389442d6a0f03f07cc8cfcce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7087efa6565846bbbc1bc32cad82ad81",
      "placeholder": "",
      "style": "IPY_MODEL_857b200869544cccb7b7b71abaaaf77d",
      "value": " 222M/468M [00:19&lt;00:21, 11.4MB/s]"
     }
    },
    "d282699301ad46a89c380cf41ddd3f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07336fc047f8452095b46069736deb86",
      "placeholder": "",
      "style": "IPY_MODEL_b57ef3ddffed441bb8eca01f226b7c42",
      "value": " 473M/473M [00:36&lt;00:00, 7.02MB/s]"
     }
    },
    "d810a787c6f14f2e85e271d40958f39c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_523b853154614b8a90e0ff7438ea2a49",
      "max": 507801845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed5eb60b68a54878bb6ecc940a8f6a08",
      "value": 507801845
     }
    },
    "d86ccec9bb2348859f061f086d066e26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc43cc63c67140e699206b14f8e0a062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01765d3ce26f41df83ee98fcbfead15b",
      "placeholder": "",
      "style": "IPY_MODEL_e5e9d1b5208e493f9556961e94781c3d",
      "value": "Downloading data: 100%"
     }
    },
    "de90fa4f9ba54b2c8d89f4c966897c37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfc65c055de74d97ab05514cdf8dc854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_659d82d731d14e4499893e4506184200",
       "IPY_MODEL_2d6412040cee4509bdafaf3a9ce6e9f1",
       "IPY_MODEL_c35cc17d389442d6a0f03f07cc8cfcce"
      ],
      "layout": "IPY_MODEL_7579f4c8b03a45498834acb1047f21c7"
     }
    },
    "e5e9d1b5208e493f9556961e94781c3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea9e9908772441d89b3a59de94daf38b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed5eb60b68a54878bb6ecc940a8f6a08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f119aa9ef39245e98b013c5cdd123a53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3323a1af573409798487e358ffbb007": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f779eb3b68c8471381e3ab8d1fa4b22b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f85183fb4b7d466495a7418e51d0cf3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "facaed99f6194d46ad018f24ae412fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33d5fabb269149f8894484bbc204bc06",
       "IPY_MODEL_d810a787c6f14f2e85e271d40958f39c",
       "IPY_MODEL_4a8ae1c437db41538c4452839d11034b"
      ],
      "layout": "IPY_MODEL_b05f23a34143457d82b70c8951225ee4"
     }
    },
    "fc7165a9d8ac456f9d93627d03bccb84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe4ec3300c4f47828618edb5320f3d54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
